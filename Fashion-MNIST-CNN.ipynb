{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c21f34ae09d0efb5f3b8b58de9005985bbb52e06"
   },
   "source": [
    "# Fashion-MNIST using CNNs and Inception-ResNet-v2\n",
    "\n",
    "The Fashion-MNIST has 60,000 training samples and 10,000 test samples. Each sample is a 28x28 pixel grayscale (8-bit) image.\n",
    "\n",
    "Classes:\n",
    "\n",
    "|Label|Description|\n",
    "|-----|-----------|\n",
    "|0|T-shirt/top    |\n",
    "|1|Trouser        |\n",
    "|2|Pullover       |\n",
    "|3|Dress          |\n",
    "|4|Coat           |\n",
    "|5|Sandal         |\n",
    "|6|Shirt          |\n",
    "|7|Sneaker        |\n",
    "|8|Bag            |\n",
    "|9|Ankle boot     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "adf03848634b2bdda11e125d4415e6519a815571"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import PIL\n",
    "import IPython\n",
    "import collections\n",
    "import hashlib\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import inception_resnet_v2\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf70406ffc74d85dc41cce327550ebc1c7628ba9"
   },
   "source": [
    "## Load the data\n",
    "Luckily, the Fashion-MNIST dataset is included in Keras, so this is a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "db87bd5aac056428753dc748b9c7d62153d30bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train_indata, y_train_indata), (x_test_indata, y_test_indata) = fashion_mnist.load_data()\n",
    "\n",
    "# for kaggle\n",
    "# data_train = pd.read_csv('../input/fashion-mnist_train.csv')\n",
    "# data_test = pd.read_csv('../input/fashion-mnist_test.csv')\n",
    "# rows = 28\n",
    "# cols = 28\n",
    "# x_train_indata = np.ascontiguousarray(data_train.iloc[:, 1:])\n",
    "# x_train_indata = x_train_indata.reshape(x_train_indata.shape[0], rows, cols)\n",
    "# y_train_indata = np.ascontiguousarray(data_train.iloc[:, 0])\n",
    "# x_test_indata = np.ascontiguousarray(data_test.iloc[:, 1:])\n",
    "# x_test_indata = x_test_indata.reshape(x_test_indata.shape[0], rows, cols)\n",
    "# y_test_indata = np.ascontiguousarray(data_test.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce22fe2ed297be91b002769eb013e2d7421b1945"
   },
   "source": [
    "## Data integrity\n",
    "\n",
    "Check that the data looks reasonable by looking at a few random samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "6f9852309d7b17199c7ac1d64169d0b284a163f9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAADmCAYAAADmze0/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXu0VdV1/78rRmN8JBEVckUigiCCoqISqmJ8P4iRxCY+2hhMTfFRrTahlaGJSUZHqzGtHbEmVjI0odHoL9VUTAc+EPCBCAERQUAFVAREEDTRGBNjXL8/OHPd7753rXvOufecvfc9fD9jMJh3nXP2XnvutR/ru+aay3nvIYQQQoji+FDRFRBCCCG2dfQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYHr0MHbOneqce945t8o5N7lRlRJp5PN8kb/zRf7OH/m8HLjuJv1wzm0H4AUAJwFYB2ABgHO998sbVz3ByOf5In/ni/ydP/J5efhwD347GsAq7/2LAOCcuwvAeADJk+ica3q6rw9/uPMhvf/++w3b/g477BBsfpH505/+1LB9dGCz937Pil2Xz/PwdwvSbX9XvtMUn++yyy7B/t3vfteMXQR22223YP/hD38I9rvvvtusXZrPS+PvagwZMiTYfB+wc/PBBx9EP+dyuy/99re/bVo9E+ieki/s7yQ9eRj3B7CW/l4H4NP1bsQ5F+xUL92+U0svvk+fPgCAD32oXYF/7bXX6q1Wkr322ivYf/7zn4O9du3a2NerUsOxrSG7IT6vtU4M1y92ztjffMPpheTu7xTbbbddsA855JBgz5kzp6n7PeWUU4L93HPPBXvx4sWdvlvL9VsD5vNC/V0PP/zhD4PNLyxz584FAPz+978PZXyfePvtt4P9xhtvAAD+7//+r2n1TFCaNr6NsKb6V3r2MK4J59xEABObvR+xFfk7f+TzfJG/80X+zoeePIzXAxhAf+9dKcvgvZ8CYAoQlzj4bZp7Avw2ad/ZaaedQtlBBx0U7OHDhwd7//33B5CVjVetWhVs3oZ9d+XKlaHs6KOPDvabb74Z7JdeegkAcPjhh4eyRx55JNivvvpqsNes2foitHHjxlC2YcMGNICqPq/m73qI9ZA7ltu5SfWG//7v/z7Yo0aNAgDMnz8/lG2//fbBPumkk4J99dVXAwCWLFlStT4d69JAGtLGayGmkFx88cXBbmtrC7b1krlH9fLLL3dntxk+8pGPAABOO+20UMZyLF9Ty5YtA5BVRPia7Sa5+bunjB07NtgzZswI9p57blUjuWfMfttxxx2DvfPOOwMoXFXK9Z4i0vQkmnoBgCHOuX2dczsAOAfAfY2plkggn+eL/J0v8nf+yOclods9Y+/9+865SwE8CGA7ALd575f1pDL8Zs2BUuPHjwcA7LvvvqGM3zZXr14d7FmzZgEABg4cGMo4qOvTn24fDjnqqKMAAPvtt18o4zGyadOmBdt6LE888UQoe+yxx4L9yU9+Mti2Pd6X9ayBbM+wnuCNZvi8yv6q2jGGDh0abFMfAGDMmDEAgAMOOCCUffSjHw02+8J6f0uXLq15v43uYeTp79ixcZvhY3vnnXcAAF/96ldDGQdXca/M4iWs1wtkg8EY67XNmzcvlLFaFWurjezJ5d2+68V6vUC2Xf7mN78J9sc+9jEA2XPw+uuvd7m93Xffvep3m0XZfb4t0aMxY+/9dADTG1QXUQPyeb7I3/kif+ePfF4OlIFLCCGEKJimR1PXA0txZ599drD/+Mc/AgAWLFgQyt57771OnwPtEhwHdbG8Nnv27GDb9nhf999/f7AtSAUAjjjiCADZaSUcfMRSkwVwpSTW448/Ptj33ntvp8/LQqpOw4YNC7b5haVplkRt2AAA9t57bwDAGWecEcp4qse3v/3tYJs8esMNN4SyF198MdjPPPNMsG24oDdPqYoFcHHAGh+bXSccmNivX79gczCXtTUOJnzllVeCzdcGD+0YLGn3Zv82gv79+wfb2j2Qvc5tqI0Dtdjm+5a1/QYEvokWQD1jIYQQomD0MBZCCCEKplQyNctALO1YVCmXmeTJnwPtkhGn9OO5w/w7i8j+wQ9+EMp4HrJFWwPtEZMsAe6xxx7B5mhWywLGn3MWMI5QtWhjjuIuGpNK2VeTJk0KNqcXteNav3599HM+Z9dccw2AbDpHjtzlYYiRI0cCyJ5blkxPPfXUYH/pS18CAPznf/5nKHvhhRdSh9dr4OEXbl+xiF2WOmOy6Lp160IZ/27XXXcNts0C4KEYOw9AY9PK9kb4etiyZUuwOZr6E5/4BIDskBsP2/DQlmH3C6A9K5fY9lDPWAghhCgYPYyFEEKIgimVTM2T6llmtMUZWGrjBCAmDQHt6fs4xeWJJ54YbJaMTEriSGBO+s5Sk0Vhc5IKlu1YUuxYbyCbpIQjZgcPHgygXDK18cUvfjHYLG1yVLPBx89SP0vyZ511FgBgxYoVoey4444LNqd8NH+w3zgimH1oqVH/8i//MpRde+218YMqKbHIdW5rljoRaD8X7GeWqfl3sXbJcj9HxluEOl8jnOaVo603bdqUOJLWZZ999gk2LwzDPrb7B7fb2DkA2v3MMzE4Ql7Eia3MF0uf3BPsvlVLpLsl37F0vwBw2WWX1b1P9YyFEEKIgilVz5gDGbhXam+ONn8XyL55ckDQxz/+cQDZdJo8d/gLX/hCsGNvoZwakxcpsEUjuPfGqeu4DtY757cq7iHyd7kXUxasx2W+BLJzU2P15+N76623gs1BbNabYL/zXG5WKAYNGgQAeP755zvtq6Nt6VD599zb4GCb3gT3fNk2WMXhnjMHL5rCxP7g1K08z9vSbPJ2mREjRgT717/+NYByzo9vFpy7gO9FsfaV8iGfRwvm4oA70U4qvW21QEIOkovNjef7Ms/l59/xfHDj5JNPDjYH906ePBkAMGXKlC7rVQ31jIUQQoiC0cNYCCGEKJhSydQsPdtcSgAYPXo0gOyawCx1stRgcjJL3hz4tXDhwmDbykA8h5Ml2JkzZwZ7wICtS36yrMdzAjnoxWyuF8uIJgcCWSm4LJiUxoESHPTDspzJcSxT8+846Mp8wFI/n3MO7LL5rzwPliUnntvJcpbBwYC9VaZmOZn9aBIa+5HTWrI/7LxxG+dUonyujjzySADZufQcCMlrG1sbTwUntSJ8DbPcHLsn8IptHPjG/rS5+duSD1PE1ipPpV/l+d42HMlBpXxPicH3KpasY9I056C46KKLgn3XXXcF+/zzzwcA3HnnnV3utxrqGQshhBAFo4exEEIIUTClkqlT0XOWcpHnFls0J9AeeQu0zzmOpQ8EgMcff7zT71j2uPXWW4PNkaK2PY4UtjnCQFayNok0tiA8kJVGLJqY5erYIu55YnXhiFCWM9mf5g8+VpacWBIySYllJP4uzxe38798+fJQxrIs78+iIDnKkqOHewPmh3HjxoUyPgaWQs2P3I74c5ZT7Vyxzzl6l2cdTJs2DQBwzDHHRLfFwwhXXXUVAOAnP/lJKGN5uxXhoRG+53AUrrXXr3/966GMo/w5n4Dk6XaqReV/5zvfCfaZZ57Z6XOWqR9++OFg/+hHPwq23VNSc4c/+9nPBvvHP/4xgOxsjhtvvDHY3/rWt4KdipyvF/WMhRBCiILRw1gIIYQomMJlapYxOXKWu/6Wku+0004LZb/61a+CzRKvRVOnVj/hVYCmT58OIJuSkT9nmdAk0FjyBSAr91kEKydf4KQZHOlt5bzdomVqS9SRWnieI8ctqURqon0s0pmPlYcTYlIVR0Xztlg2j8nfvUGmtuhlADjnnHMAAPPnzw9lsWME2uVSjvxn/1t6UKDdv9zmfvaznwXbUpQC7f596qmnQhlHUHN9bLsXXnhhKLv99tuDzclcWgVeeY2vbZb9rW2bzAkA3/3ud4PNsr/d42LpHbc1UhHOxumnnx5svs4tApqHDLn9s7z90EMPAWgfYgHaE3YAwF/91V8F22YcnH322aEslQLWzl9PU3JW7Rk7525zzm1yzj1LZX2cczOccysr/+/W1TZEz5HP80X+zhf5O3/k83JRyyvZTwHcBOC/qWwygJne++ucc5Mrf1/ZnQrwGz2/NXJwg9n8RsTBPvzGam+pvDYyz0/mN30LPuK0ltyjis1x5UCZVIo2C8bhY+M6ckDHYYcdBiDbI0rQMJ9Xw5QGftPj4+Mgtticau7F8dw9OzccCMO/i/Wi+Xyk5gTa77h9pBSMOmi6v1n9YUXGYJ9zz9bmp3IbZ3WH079aUMrnPve5UDZ+/Phgc1CWXSe8X64jt32Dzx8HKXaD3Np3d+H52Zdcckmwud317dsXQPZ6ZgUjlg6Tr4ecKY3PY3OKeaEaDhrl+7n5k58XvKgNK6S2kAMH8fK5mTt3brB5vfRqNGqd76o9Y+/9YwA6ar7jAUyt2FMBfL4htRFdIZ/ni/ydL/J3/sjnJaK7gxX9vPf2evIagH6pLzrnJgKY2M39iHZq8rn83TDUxvNF/s4f3VNKRI8jB7z33jmXHK323k8BMAUAYt87+OCDg82BQTwAbjIOBzrwgD/PEzb5miWzT33qU8HmuZC2j1SaOy63VYK4jNc3XbBgQbBNUmRJnGUYll5txaF61jHtyufV/F0L5gOWmznQqsP+UNlXKEvNF7cgiyeffDKUsZQf20YqtR3vI7b2aCNXw+ppG0/BAXImb7IEx77h9b1NkuMAsFmzZgWbrwcbEkkFH/E1Ze2SVy6zucdAtj1YHfj3XPee0Cx/95SlS5cGm9Na8nmyIZ5FixaFMpah+f5hv4vJ/3nTjHtK6j5g8PUeC3i65ZZbgs3ranM7tGuft8/PBt6uXW8sTfPveNjHzsnPf/7zUHb55ZcHm4dvLG3tFVdcEd3Weeed1+nYYnR3atNG51wbAFT+3/ZWGs8f+Txf5O98kb/zRz4vEd19GN8HYELFngBgWhffFY1BPs8X+Ttf5O/8kc9LRFWZ2jl3J4BjAezhnFsH4NsArgPwC+fcBQDWADgrvYWuMZkWyEpxvOqJRdKxDMkSHa+gcfTRRwPIShkcFR2Lpk7Np+UFxE22GDZsWCjjlYx4f3YcttoUkI3+feyxx4LN0leCkRU/N8zn1YhFU7PN8pNFEnJ0Ow8RsI9sG6nhhhixCGuguqTNcmCd5OZv9pPJXix/8fx5jha1YQSW4m1+PZCVmU0K5UhgllV5qIXbsMFzaHkYySRpvh56kN5xD+TYvrsLS6V8nthH1ga5LfI1wNh3UjkRmkgubTy16lI1rrnmGgDZlcpY6uehxNhKSyxN833C7juxIa6O9bX0mpye9stf/nKwedjH7ms84+HZZ8NM4Jqp+jD23p+b+OiEuvcmusMS770lzJbPm4/8nT+bvfdbIH/nhdp4CVE6TCGEEKJgCs/Dtnnz5mj5Aw88EOwBAwYAyK7gw6kxeTWfsWPHAsjKdryiB08IN9mCEy6wbMFy38iRIwFkE4SwbHX44YcHe86cOQCAe++9N5Tx78qOyaMc5WkpMoHqkZE8CZ79acMBLOGlUgHa9lIRmTGZmuUplg7LCvvJ5DauNyc6YFm0X7+tM1C43bJsxukALZ0op/I7/vjjg33zzTcH22YEnHjiiaGMpXA+F7Y9lgxZxm7FFYm4/W3ZsiXYPETD9xdj7dq1webzaHYPk6X0KlJpL/k+YOkqFy9eHP1dzMf8+2oryKXuObxdG8rh64bPE2/DzmPqu7WinrEQQghRMIX3jPnNJTXvzN4s+Q2TA7FOOeWUYNt8TV6Ygd9YOJjLAic4cIXf9Pl3tqjEgQceGMp4fWVOEXnooYcCABYuXIgYsXlw3Q12aAYW/BRbQxfInht7C0295fLv7BhN6ei4j1hvqlq6TN4f16EB6TCbTmwOdWrBDX7TtnmNPLf4pJNOCrYpM0C7b1hV4rnD7HNTLjjAkHvvfF6tPnz+eFGPdevWdTq2VoKPm3vGfI8yuMfFbdR6VGW69htJ7D6XWkvYFnEA2td85uAsnhsf82cqXwFj7Ze3y9894ogjgm3rGPN2Uyk37b7EdexOAJd6xkIIIUTB6GEshBBCFEzhMjWTCtAxqZPlBZ6fzKkabdCfZSQLeAGyEqvZPA+QA2hYFrV9swzFadU4MOPpp5/udGws17I8mZJUiiQmB7NfqgVP8ed8Ti2ojuWrWIAFEJefeFu8P/Mtnw8OJqqWlq8ouM3Y8fKcUw6e4vZjx8nXA6fqu/7664NtUvYxxxwTyliyHjFiRLAnTZoEAPjHf/zHUMapW7k+dl5iwTTbAtxWuX3F5gxzcB23594U1NkdUpK0cccddwSb26Gthc3z7Pl+HpsnHJtP3LEOdt1wqkoeMrvsssuCfdNNNwHIpjnm4YjYEBPfk/jarhX1jIUQQoiC0cNYCCGEKJjCZerYah0dy2OLN/Oi6GPGjAn2U089BSArB3FqxFjKRJ6vyfviyGuTM1iW4xWgOC1gTKJISfCp48+bWNQzl7Hsy/KoydfsV/Y9RwGbv3kOOMvf/DuDZaZqEjPLqBz5yHVPrT5VNHbs7HO2uV2aT1huO+OMM4LNaVj/6Z/+CQAwe/bsUHbxxRcH+3//93+Dfd111wHIrvrEqWJZ/out7JWKdm9FOFqfU/PGpGeLDgaACRMmBPvRRx9tUu3yJTV3mFfLu/TSSwEAxx13XCjj69KkaaB92JDvjXzP4f3ZNc/3n9QwoKU65vPB6WBj92JbaQ7IrkoWez6xrM73uFrZdq4eIYQQoqToYSyEEEIUTOEydS3E5AOOnF2/fn2wLfkGJyBgyZJlNZMGOXkHb5ejrE2uY3mK7VSqtNgxlCmi17BkKUC7zM6yL8ukXH+Tj1LRpSwZ2e/Yryzpx1ZzYr/xPmIydEqC5sn4ZZKpY35KRaByu7VjZ1ns4IMPDjZH9J555pkAsikyp06dGmxOc2rsv//+wbZkN0B2RTM776k0qK1ObIUfAJg/f36n7/KKWRxZzXZvwq5T80Hqfvad73wn2JaYiYf2OEI6tvJVavYED2fZ9RJLRARkh1zuvvtuANmo6RR2r+EIapapY8mqenpfV89YCCGEKJhe0TOOzcXlNyHuoVpyfX7T4s/57cXezLh3wEEHHKxl62lyr46DCnjRiNj6pal5uLHPi4B9ZG+bqXmubFsvjIPd2Mf8Fmtvm6n5wPw7s7k3zP7mt19LD8lBfdzL5rqVidh8SQ425HbCi0aYz9gf3OPn83bAAQd0+pwDv7gOvPiBwYGJfN5iCkMqAX8rwtcL5x6IrU/OPWNu46Y0lHUefIpaFRAOYrLANlYQUykuY7kLUmug23f4nmT3AyCrAtkCFAz/jq8nU514TftqORGY2DzkaqhnLIQQQhSMHsZCCCFEwZRKV0rNv40NkHOaPg4CMpmPZQSWOFhqM4mCZSKTo4GsHGPSM8vf/DnPVTb5ad68eaGM615GWYrlZJNYWN5lH8bk4tQc09icZA6KSK37GVvlJXaegfZ0pzxXkffLsm2ZiMnn3O55JTD2f+z8cDvidmnf5WAvlgRZTrNritNl8rANS+UPPvgggPRc6FaEh1T4/sJzizkoyeAhrD59+gR7r732ApC9HmLpNMvEjjvuGO5vp59+OoD4cAuQXQ/ehjX4/slDHbE8Bangzdh3eaixmjRdC3ZOUqk1+ZjtGkgFudZK1Z6xc26Ac262c265c26Zc+7ySnkf59wM59zKyv+7VduW6BZ9Afk7R0aojeeO2ni+yN8lpBaZ+n0A3/DeDwcwBsDfOeeGA5gMYKb3fgiAmZW/RePpK3/nygqojeeN2ni+yN8lpKpM7b3fAGBDxX7bObcCQH8A4wEcW/naVACPALiy3gqkVi2qljKSJbPYfM1Y6j4gKwPF5BD+LkvWNreTJanU/GWL5uOoPp5TWKdM/S4a6O8UsahlrhtHPrKsZsfF54PlGj6PJhfzdln6iUnlTGouocl9XMbnps4o3w+w9YHcdJ+nIv5jcIS+ycwsmzKx42XZnj9nP5n0z37kRdInTpwY7FtuuQVA9lxyG2BptgZyaeM9hY8vNi8WiKd0Zfg6s2EGLsuJbvu7ra0N3/rWtwAAn/3sZwFkpXlupzyn2IaY2G/cdrhNms1+YTs28+PGG28MZf/+7/8erbu161RqYmbo0KEAsueT72tcXyvnZwtfV7VSVwCXc24ggEMBzAfQr/KgBoDXAPRL/Ez0jJ0gf+fJDlAbzxu18XyRv0tIzV0G59wuAO4BcIX3/q0OPVfvnItOlHXOTQQwMfaZqIm18neuDAZwnnyeK2rj+dJtf8cytonGUNPD2Dm3PbY+iO/w3v+yUrzROdfmvd/gnGsDsCn2W+/9FABTKtvpVmaLmExt0iSQlQ/suywvcANavHhxsC2ykSNNU/KCSRyx1Y2ArIxrss1XvvKVUMYLvsciq7uQq00rb6q/+cKMrdrE/mQ5xuqfiqTl4zJ/s/TJck/MB6mJ/xs3buxUd/6cI4brlAHfyKuN84owMVhaZknajo0jynl1JZYCzSepGQUcaW6R7ZxC8Omnn47WzSJlWaLk4+GVcWoglzbeU/gaqCZH1wJfXznTI3//9V//NYD21arGjh0bvsttYNCgQcG2+yO3TZOCK9sNdizNJs9W4VkqkydvHeauZViknghnG4qLrRAFxCPI+Xh5iLJWaommdgBuBbDCe38DfXQfAFsPbAKAaXXvXdSD/J0PG8mWz/NF/s4X+btE1NIzPgrAeQCWOuesW3kVgOsA/MI5dwGANQDO6k4F6kkDyW9Vtr4wEF9DlIOMXnnllWBzsm9by5LL+I03tmgE14GDsnhhCkvL+JnPfCZ6HKk5xwmGO+fGoUH+ThF700/N1eb5vLaoAM8B5jf+WIL3lLrAwVz2O35j5jpyz9gCaPicb968uctj64LhlXbesDaegt+kY4tzcNtg5WXdunUA0otKcG/V/MsLgTCsBFlgDLd73i/3kq1t8754TnKd5NLGewrPiU/1kqvNE46ds9j6502mIf6eO3du5v+usLbMAV6pFJemsrG61Z2AqFpIpa38n//5HwDZZwPfc2LpMDnAb8GCBXXXpZZo6jkA4iFnwAl171HUy3LvvS2dI383n+Xe+8Ppb/m8+aiN54v8XUKUDlMIIYQomFKlw2RZjuVJkwF4PVX+nOUjCxJi+YHXZzWJD4ivyZqa92rSHdeRgxVYUjHZib978sknB/uhhx4Kdg0BXLkQk4lYkmdpmVdj6fgbIC292+9YcmLZistj6/vyd1lKtd/xUAEHiTUi2KYZxFasYt+xn9n/1r5Sx8XbNd9w++Jrg2Vx8ynLbRxkw6tiHXLIIQCAJUuWhLLRo0cH++abb47WrTfDQXKxFcaA7H0gRkwWjaXQbDXMR5zitQyk7rt233n00Udzq4t6xkIIIUTB6GEshBBCFEypZGqOvI3JByNGjAj2pk3tU+I4WtpkapY0WYKNpVxkudlWAAKAOXPmBNukcJZNWV7iFXRMJly0aFEos9RxQFamLlqeNtj35hf2G88bZR/a0AGnDk3NHbZo53333TeUsdzM0dAme7N03dbWFmyWoW3xdo6wTy0EXjQ8p52HAaxdpVZi4rny5hP2cyoVqEVRs8Sa+q7NW+bv8tCQ+Rlol6Q52nRbSgjB135q5bEYsZkfQgDqGQshhBCFo4exEEIIUTCFy9QsJ8YWUAfa0/NxlCfLa8OGDQu2RaCypM3RpZxi0Cbo8yLYqdVtbN8s8bHMyBP37Xe8eDbLsbaIOwBs2bIFQPVVqpoNH5fJbnz8nMyAU4rGEhawX/r37x/shQsXAshK/bwCC59fk8U52pfrwynx7FxzNDW3nwKSKiQZNWpUsGNDHjwEwPInJ9+IDW2wFM+fW3uOrYoDxNstS8/HHHNMsGPRxHyuORkMHycP17QKHBVczzBIavU2IdQahBBCiIIpvGfMpNbB/dznPtfp81Sgi/2O30A5aTf3MOw73DvjXsPatWuDzT00g9+IeS5zbL3ZNWvWBPvMM88M9o9//GMAxfSGmdjauBy8wz1RptqCABywsn79+k6fc0ATn1OeD14Nm4PLCxzw8fA+ioYXOOFepfUkZ82aFcp43i73kmOLlnAvO7bwCf+er4eYasAKxZgxY4LN6o5tg4Pq+Dr68pe/HOxW7BnzPaeeeewc6NidxQRE66KesRBCCFEwehgLIYQQBVMqmTq1dq2l3ON0fDafGMjKaibRsYzEc1KffPLJYL/88ssAsoEnvF8OwIpx+OHt6wmwDG37e+KJJ0IZB5xxAFdZYEne/MkrH6XWtTV/pdID8tCCybIsjaZWwjF4uIIDXliWtbqdeOKJoYznnvOc9KK54447ouXWbtlfPO+arw0LsGI/8rxXlqnt/HDA0ciRI4O9dOnSYFsAHPtu5cqVweY1Za1tr169OpRx6kBuO60It9t6Ariqreoktl3UMxZCCCEKRg9jIYQQomBcnlG8zrnXAbwDoFU1rD3Q+GPbx3u/Z/Wvdabi7zVoTr3KQqOPrdv+BtTGu0lP27j8XR+6p3RNIfeUXB/GAOCcW9hh8faWoazHVtZ6NYIyHlsZ69QoynhsZaxToyjrsZW1Xo2gqGOTTC2EEEIUjB7GQgghRMEU8TCeUsA+86Ksx1bWejWCMh5bGevUKMp4bGWsU6Mo67GVtV6NoJBjy33MWAghhBBZJFMLIYQQBaOHsRBCCFEwuT6MnXOnOueed86tcs5NznPfjcY5N8A5N9s5t9w5t8w5d3mlvI9zboZzbmXl/92qbauJdZS/862j/J1/PeXzfOsofzcL730u/wBsB2A1gEEAdgDwDIDhee2/CcfTBmBUxd4VwAsAhgO4HsDkSvlkAN8rqH7yt/zdsv6Wz+XvVvN3nj3j0QBWee9f9N6/B+AuAONz3H9D8d5v8N4vqthvA1gBoD+2HtPUytemAvh8MTWUv3NG/s4f+Txf5O8mkufDuD+AtfT3ukpZr8c5NxDAoQDmA+jnvd9Q+eg1AP0Kqpb8nS/yd/7I5/kifzcRBXD1EOfcLgDuAXCF9/4t/sxv1Tk0d6yByN/5In/nj3yeL2Xxd57vMAc7AAAgAElEQVQP4/UABtDfe1fKei3Oue2x9STe4b3/ZaV4o3OurfJ5G4CiFtOVv/NF/s4f+Txf5O8mkufDeAGAIc65fZ1zOwA4B8B9Oe6/obitq97fCmCF9/4G+ug+ABMq9gQA0/KuWwX5O1/k7/yRz/NF/m4mOUevjcPWiLXVAK7Oc99NOJajsVW+WAJgceXfOAC7A5gJYCWAhwH0KbCO8rf83bL+ls/l71byt9JhCiGEEAWjAC4hhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYPQwFkIIIQpGD2MhhBCiYHr0MHbOneqce945t8o5N7lRlRJp5PN8kb/zRf7OH/m8HDjvffd+6Nx2AF4AcBKAdQAWADjXe7+8cdUTjHyeL/J3vsjf+SOfl4cP9+C3owGs8t6/CADOubsAjAeQPInOue49+etgr732AgC8++67oey9994L9g477BDsHXfcEQDw9ttvhzJ+OfnDH/7Q6XcffPBBKPvjH//YqGp3xWbv/Z4Vuy6f5+HvGNtvv32w2Z/vv/8+AOBDH2oXZHbZZZfod/mc5Ey3/V35TiE+TzFs2DAA2XPC18Pzzz+fe50imM9L6e+PfexjANrvFwCw6667BpvvCb/73e8AAB/96EdD2XbbbRfdrt1fuK3b75tMQ+8pzrmqO7Rrm79brSP4kY98JNgf/nD7o+qdd96puj+D7zV2Trj9/+lPf4r+zurJdUzVPfbdDrC/k/TkYdwfwFr6ex2AT3f8knNuIoCJPdhPXVx88cUAgGeeeSaUbdiwIdgDBgwI9tChQwEAs2bNCmV8YS1f3t4eP/WpTwEAfv/734eyVatWNaraXbGG7Ko+z9vfMfbYY49gcwPdvHkzAGCnnXYKZX/xF38RbHtYA8DMmTO73Ec9F3Wd1OXvSl0K8XktPpg6dSoAoK2tLZStWdN+iGPHju3WdhuMVaiU/h4zZgwAYMSIEaHs2GOPDTY/HJ544olO3/3EJz4RbPbtsmXLAACPP/54KHv00UcbVOsuaeg9JfXyzcf65z//GUD2oVqtM8P36r59+wZ77ty5Xf6O4Reogw46CACwdm374a5fv77L3/HDml+q+F5lx9TF8axJfcD05GFcE977KQCmAOXrNbQi8nf+yOf5In/ni/ydDz15GK8HMID+3rtSljssdZ588skAgHHjxoUyewMFgBNOOCHY1lMbOXJkKFu8eHGwjzjiiGBbz4LlqcsvvzzY/KbURErj845wb/fSSy8N9iGHHBLsN954A0D2DfPII48MtqkaQPubKQ8VMNV6bA3q3ZXW30D6uLg3MGTIEADZt/bhw4cHe+eddw629fBy6g3HKNTf3MP7r//6r2C/9dZbAIAXX3wxlM2ePTvY5557brCPOuooAO1KGgA88sgjwZ4zZ06wTS49++yzQ9n5558f7AsvvLDTd5tAj32ekqm5HZlcnOo9mt8A4KqrrgKQbacs37OSab1Svv/26dMn2Ow3U0L79esXypYsWRLsK6+8MtirV6/uVEc+Tpa/G3W99CSaegGAIc65fZ1zOwA4B8B9DamVSCGf54v8nS/yd/7I5yWh2z1j7/37zrlLATwIYDsAt3nvl1X5WVMYNWpUsJ9++mkA2TeiF154odPnzG677RbsBx54INiTJk0K9m9/+1sA2TGG/fbbL9jPPfdct+peD0X6nN8K99yzPRbBgiI4COXZZ58NNveMTa3gcfd777032Pfff3+wLfDIetNAdmyuWhBHI95Wy9TGY3Aw4ne/+91gn3HGGcG2sbqUUjBv3rxg27n49re/Hco4hqLZFO1vvt7ffPPNYFvvie8TPJZ4zTXXBNuUHO7J8XinBZgC7edv0aJFocx6bwBw1llnBfv222+v51BqptE+t/YGZNunBdSyErNixQquR7C3bNkCAHjttddCGfv+C1/4QrDtvsNj9NxzPvjgg4NtY8V8Dx80aFCwp0+fHmxTRv7jP/4jlKXGj7mX3BN6NGbsvZ8OYHrVL4qGIZ/ni/ydL/J3/sjn5UAZuIQQQoiCaXo0dR7wXMkvfvGLAIAZM2aEMp6+wVMHTM5gKYMlp7vvvjvYu+++OwDgscceC2U8hacVYXmNg4I4WGvTpk0AspI9y9jf+MY3gv39738fAPCVr3wllJ1zzjnB/vSn22dU2LAAS1283/79+wd73bp1ALLy97bAhAkTgj15cnvipFdffTXYJpvylBKeg8/n6pvf/CaAbMDjXXfd1cAal5uPf/zjwWZJ0qTM119/PZRxIJJNmQHaZVoOBuNt8fCZDQHwnORUfXoLLNlyOzM4mI0lbfatDanw0BffB2LztjnwjX3Pww12LbAkzsNgPAX2a1/7GgBg/vz5oYynVPH9MBVkWi/qGQshhBAFo4exEEIIUTAtIVNz9OjKlSsBAAMHDgxlLLUdd9xxwbY5xfvss08oY8mbv2uS0t577x3KFixY0NOql5LYnGqWc0xCZvi7LOewhPNv//ZvALKSqc3hBLJR8ZaViD/nfXC0qs2l5XPXKOmozPziF78I9j//8z8HO5YdiMtYSmQJ1eTtX/3qV42vbC+AJWTOWGZtyYZDgKzEypH9MX+zzfswOZWvBx5qYWm2zHDEfWoWwxVXXAGg/VoFsvO2YzI0y/d8H2CZ2srt3gJkZ89wtjnbB8vYXHc+p1Z+8803hzIezuRzbtvl33cH9YyFEEKIgtHDWAghhCiYlpCpDzzwwGDbRHFOBs5RfT/72c+CbZG8LDdzJCmnY/v1r38NIL3oRCsRS+TBK6iwBGxyDkcdsgzEcvIrr7wCICs333PPPdF9mJTKkhRLSrHVsziimxOPtCq2mhCQXpXJ/MRSKMN+NP9zpGg9K+T0drhd8nCURVPbIhAA8MlPfjLYLE+an9mvLMHyd+0640Un+F7EaRvLDA97cJQ5X8+W2pOjmzmRB99XzS+8XR525H1Y6kuW9/k88nmy+w9HbnMqZZsxA7Tft/i6+Yd/+IdgczKQRqGesRBCCFEwLdEz5vRmFgTEPS5e8IHfTF966SUA2aADTlfHCeBffvllANk3Xk6l1tvht1ibz8tvoBy0xf6KLY3GvVlePs7eWO0NFcj27mLrSnMaR94H9zYsQIZ7dNsCPA+Vfc4+sx5zLcEltg3erqUmbFU4PSP3rrhnbO2KU1VyL4qvjdhCCHw+ODeB7ZsXNuAFJjhoqcykUqZyCk/rBXPPmH34m9/8JtjWM2a1Z8qUKcE+/PDDg23BWoMHDw5l3NvlBR9su5zPwBYLArL3QGsLHGTGC9nccsstnb7bU9QzFkIIIQpGD2MhhBCiYFpCpub5XyZLsPxgKRuBrLxpKzjxKiAsWz300EPBPvroowGkA456OzGJl2Uili7ZNonNJH8gKzeztGwBb3w+OIiD5SWT8/i7LAHyebSApVSQUqvCQWocaMXzM03CZ9/wMAO34di6va0OzydmuZWvhzPPPBMAcMEFF4SyVIrL2LZSq/rYcNC//uu/hjJeI53X2rVrLjbHv2jYFyyz833ZhhL5umUf8X3A2iHL+zz3ndu93TNS87p5XWobcrnppptCGQfJ8TVi7YLvZXyPu/baa4PN56wnqGcshBBCFIwexkIIIUTBtISux2kUbS4gzznlyEiW4E488UQAWUmKpRNLrQkAS5cuBZBdKacZc82KgqVNm0fMEg7L/jx32OZ1szTEPuSI0OXLlwPISlkc7chSldWBV2ri88j1iUmxLL/GIlxbDY7S5Xn15huWpmPR1kDW/9sKPH+VrwGen/rUU08BACZNmhTKeF4sy9DW9rmM2yK3UZN3OcKYV9Hifey7774A2lP4lpUf/vCHweZjNSmf77UsAfP1bPkdeAYA+2XkyJHBPuaYYwBkJfF777032AcccECwb7jhBgDZ9Mc8d5xnedgskFR9Dz300GDbEOacOXPQE9QzFkIIIQpGD2MhhBCiYKrK1M652wCcDmCT9/7ASlkfAP8PwEAALwM4y3v/ZmobzYYXrLYoOJaJeEI4yw6WGvPqq68OZZw8YcyYMcE2ycTSYgJZKavZ6Reb7fPYSiicDnTjxo3B5ghnS+TBv2fJmstjEaEcvc5ysg0n8O85apXla5PN+Zzz592RqcvWxquRitg1WJpOrazD38mbovzN8idH83N6V4NlVx6qia1axO2W4WEBY968ecHmREJ8r2pGasxG+Zylfk7kwRH+JtVzO+XIar7XcgS0wdI0fz5t2rROdWDZ/7DDDgu2pbPke5mlRAaAk08+OdgWOc3Hw+eAt8GJonpCLT3jnwI4tUPZZAAzvfdDAMys/C2ai3yeL/J3vsjf+SOfl4iqPWPv/WPOuYEdiscDOLZiTwXwCIArG1ivuuDFHSwo4oQTTghlnLqMB/ofeOABANnBeE6BOX369GB/5jOfAdD+JgZkU7jlQFN9zm/s5kMOtOJ1QXltY3vj5Z5AKll8DE6HGQsy4kUpOG0gz3W2dWZTPWN+U66DUrXxaqTmERupXi/36vhcFEAh/ubAN+6J8prcBis+DLfxWNrRVC85NrefFTZW3rjtN5CG+NxSBQPAaaedFuy/+Zu/CfbZZ58NIHscfG3z9frggw8CyN5n/vZv/zbYZ511VrDtXsVqHd+3eFEIy3PA920OkovVjZWKH/3oR8Hm9cMbRXfHjPt57+0oXgPQO5YX6d3I5/kif+eL/J0/8nmJ6PHUJu+9d87FB6EAOOcmApjY0/2IdrryufzdeNTG80X+zh/dU4qnuw/jjc65Nu/9BudcG4BNqS9676cAmAIAXV1gPYGlIVvbmGVVlvD69u3b6fccQMED+kceeWSwn3zySQDAuHHjQtlPfvKTnlS7XmryeXf9zcEUJu2wxBNbsxVoD3rhlUs4uIXnBpuMzJISS38s25lsxVLVRRddFOwZM2Z0+h0HeDUgNWap2ng9sPRs8nSsrGN5wRTib24nHKzz/PPPd/k7HophidVkU75eWKbm6yQWlLVq1apgs2zapLWNG35P4eBMzsNw8803A8imHj7//PODzcFeln6Uzw3fJ0455ZRg21Bj//79Q9n+++8fbB5CsH2wL7n9s2xueSWOP/74jofYCatnahijVrorU98HwLJfTAAwrYvvisYgn+eL/J0v8nf+yOclourD2Dl3J4AnAezvnFvnnLsAwHUATnLOrQRwYuVv0RxGyue5In/nzx6Qv/NEbbyE1BJNfW7ioxMS5bnz+OOPB/vrX/86AOAHP/hBKLN0ZUBWkjZYkmIJz1KiAcDEiVuHTJ577rlQxhLsokWLulX3Gljivb+1YjfU5ywDsUxtEaacypLn0nE0Ymz+IMs97C8bImC/2eLgHbdh2+W5nxxRySvamGTIx9CDFbWa5u+84GhqO8csm5ZQpt7svd+CAvzN0iK3NU6NGfsuw741f6ai13kbdp643XJKUpa3+TsNoKFtPCbTA1kf2D3hzjvvDGXf/OY3g833GhsK/PnPfx7dLs+OsDSh7Fe+n/P8Y0vdy9u68MILo9vllJoGHyfvLxZB3x2UgUsIIYQoGD2MhRBCiIJpiVWbWN60lZbOO++8UMYLU7McYlG4r776aig76KCDgs0T/211j6effjqU3XfffT2ue5Gw1MISjEUlc3QyR0izLGMLdvPvWVJjScjKOWqav8uJR2LSD6fB44n9JoGxPL4trEDEqf4YPq8mU7NkyHbMzxyNWi2quLfDwxmcZIPb5SGHHAIgKxtzW43NAmBSkqZFHo8ePTr6XUs1C5RmOCEKR4izL6rJt+wrjqa2WRxr164NZaee2p4Eku/Xdv4s+hnIzpjh7VrCJ66vpb0EssNnsQQ4qfMYGwrqDuoZCyGEEAXTEj1jng9rc8h4bcqvfvWrweYAAnvz5B4Vv4Hy26+9efHcY+4Z8xtYb4Tf+mzdzlTAAvvL/M1+4x517A2T1YnUuq8WlMXngBfpsHVMgfbeN/dcUoshtBJHHXVUzd9NrWfM5XbeeG5lq/eMYwukANngTQsSSqV55TZqvSTeLqtD3Huy37Eax59zEFm1hUCKJJUOtFqdebGF2Jzi2267LZTxPZwXBho2bBiAbKAWq5ec0+Dzn/88gGzQFquffH65LRislvA9sFGU9wwLIYQQ2wh6GAshhBAF0xIyNa+8YbLoihUrQhnPLT7iiCOCvXnz5k7bsnV0gWzQ0tChQwFkJRKWLXqjTM0rH7EsYxJMKggqFkySCl7g4BSTolgaSknhNueTpSzeBwdwmdRqwWRAPO1pq7HPPvtEy1keNN+kJEOWrK09N2p91t4AHytfzywzW5pMlptZmmWJ1cpTQXIsPdt3OeiJ7zkcwGUrDvUmqgWdsbzPQVXmO1uNDcgOp3Bgl+VEePfdd0MZ31O43HzLK2PxOeXvsm00e66+esZCCCFEwehhLIQQQhRMS8jUzDPPPAMgO2eMYVkqFnHLkgMvLP0v//IvALJyUTcXrS8NqRR7Jpux3MMr2syfPz/YJmlzKkGWn+bMmRNsk3lYYrYUdR33Z9/lOrI8ZXMGAWDw4MEAshIfzxnl7bIc1ttJDSOw3B87x9XmGXMkcavDcjO3S05va3JxLStfmbzJwwIsefO5se/yeeTodV4hjqXs3kIqJahhEjOQlaTNRxzdfOyxxwbbhgwBYPjw4QCyq0Wl5i/bPYFne9jMESA78yO26lvqeKodZ62oZyyEEEIUjB7GQgghRMG0nExtshNHRXME9ezZs7v8PcumPBnfUg+y5MRyHq9k1FtgeYWlG4uy5ujkL33pS8HmZCcm1XNkdkomtX2k0vyx1GTfZR9zxPeTTz4Z7DfeeANAVirn49l5552D3UoydWxlISCe+pKHZFIJQAw+P63ORRddFOzLLrss2DzUYmlY+d7An8ci1fk+wZ+zbW2Rh1wuueSSYF9//fU1HkV5iK0YloKvZ75nmI94JgVL2vvtt1+wTd7mYSmG27fdX/iekjo3lsyIaXYiIfWMhRBCiIJpuZ6xvY3xwDzPGeMUgrfffnun33MvitfataAA3lYsZVpvgufYcYCIlXPKN1uAA2jviQLtwSccbMGBVPzGa/tgv/Ecce5dxwLDeF74woULg21BeXzOuUfeqqkxUwF49QSUxL7LvbptCb4eGGuDqV4UqztWzp/ztcGYnzmIrMxpL+ul2rHwdckqj13nfJ/gwFlus7aP1JrQrPLY9rhefN/jcu6Jx+rbDFrnzAshhBC9FD2MhRBCiIJpOZnaJB+eT8yBBBwkFIPnu/FAv0mgtoILUO41RmuB5+OxJG1yDctnPKeag6BiqzKx3MNztYcMGQIgm6o0Jf2YfMTnjoPkeFWu/v37AwCWLVsWyljSrhZI0lupRabujrSWCgxrRWrxlbVnDtqqBkve1eRabp88xMOYpN3TNXObTbU57Azff/h3e+65Z6ffs19i65bzueFAO55nbPctvmel1lCv9pxoBlV7xs65Ac652c655c65Zc65yyvlfZxzM5xzKyv/t/5q7sXQF5C/c2SE2njuqI3ni/xdQmqRqd8H8A3v/XAAYwD8nXNuOIDJAGZ674cAmFn5WzSevvJ3rqyA2njeqI3ni/xdQqrqd977DQA2VOy3nXMrAPQHMB7AsZWvTQXwCIArm1LLOli1ahWArPzAkhFLmTFY4mBsbtujjz7a0yrWy7tokr9jUYlAu/zOUYmrV68ONkcgmrTD0lFKvrcobJ6/nJJaLQqbI3vZZqnppZde6nQMLLH36dMn2KnzS3yArQ/k0rZxoxHye0yaTZ2TJtK0Nt5d+J5h0dCpCGrG7jupaOpY5DXPOEil2G3wkFgu/q42RMLSM8vJNiTIEc0855hzCNi1zbNc2J/8HLBVztiXPJzF7T41XNBM6rqanXMDARwKYD6AfpUHNQC8BqDzLOmtv5kIYGL3q7jNsxPk7zzZAWrjeaM2ni/ydwmp+WHsnNsFwD0ArvDev9Uh8ME756KvQd77KQCmVLbRmhM+m8ta+TtXBgM4Tz7PFbXxfJG/S0hND2Pn3PbY+iC+w3v/y0rxRudcm/d+g3OuDcCmZlWyHky24Mi4xx9/PNicSi0Gr9Zy3HHHBdvkDo6mrkW2agAWQtxwf7OMxJHjJiNzEo6nnnoq2OzbmFTKcjKnJbUhhLFjx4ayefPmBZsTfJhMxJIT15dlcZOXODqT65VKupDgjbK3caO7CSJi6TJTn+dE09p4I4i1n5TvTd7mayA1ZGblnKwmJ0rhb5aW+f7Zt29fAFm/8IpafC+ypB6pITdO4mRJP3i7LHmzLF5P5HyjqCWa2gG4FcAK7/0N9NF9ACZU7AkApjW+eoKQv/NhI9nyeb7I3/kif5eIWnrGRwE4D8BS59ziStlVAK4D8Avn3AUA1gA4qzlVrA8bkOc5qZz0e+7cuV3+nt9ceb7l/vvvDyDbU8tpnvFw59w4NNnf/IZoaxdzqkpeS5h7zBbMlfILB1JZQBgndeceLPd8bbvcw+Dvcqo8e/vlfdWTsL4DwyvtvLRt3KhlDnG1Xm5J0i/m0sZj1OLD2JzTWCAW0H4dpBaS4OvE2uurr77akHrWQdP8zfWs1rbYh9yDNd+xAseBVpxDwnqz3NtllY+3YcGbHNDJ9z3+biwdZrMVo1qiqecASNXihMZWR0RY7r2fXrHl7+az3Ht/OP0tnzcftfF8kb9LSClei4UQQohtmZbLE2hzWTlQ6+GHHw52tVR/LHfwXFYLauL5br0dDqBgidcCoTjtJcvFLC+ZzMPBUyz9sERsQVcsB/E+WA40OY+DunhbPF/YZHWWBlkOZLuVaIR02aorWjUSa4Pcjrjd8rx7a+Msu/LvuA3b73iObW+nnnSYmza1x4sNHDgw2DbEmAqCi61xnvIhb8PuE1wvvpfx3OIa8hEEGnUNqWcshBBCFIwexkIIIUTBtJxMbZFygwcPDmWcfnHatK6j91kW5ai7J554AkDvX6mJSUUnW9QzSz+cKi4WScrSNEdRsnxtc7R57rFJR0BW7jNpLyafA1mJ3eYasszEv2ulc8awdMfHGIv6ZCktNc/YvlNAOsxSY9cDy6rse25rJoHyovY89MXlto0BAwZUrYOdpzIOK1Rb7SoFz8rg1Lt2rCwncztl6dnmgPP54PsaDxHYvZ2vFR625Hs/y+axOtRSXi/qGQshhBAFo4exEEIIUTAtJ1NbNDWnwORJ9QcddFCwH3jggU6/Z1lj5cqVwbYIPpOrWwGWe/i4TR7iFHTz588PNstullAllWQjlraS5WROslJN/uYIVpa6DzjggE775aQvfJytBEue7KdqUmZKVjP/b0sydUym78iaNWsAxOXojtuw4R4efuH2x9eDbY8T6qQoozwdg+vJtvmA/Xb//fcHm/1iCT5S24q131RiH76vmSSdSqvLwwUPPfRQp22l6qBoaiGEEKJFaLmesb2BtbW1hbL169cH+7DDDuvy9/wmNWrUqGDffffdALJvx72d1CIMVr733nuHslQPllNmVuPll1/uTjWrYoFdHODFvY1YartWgNOKxoLfgPiaufxWz4Evdu3079+/8ZUtKbX0diywh9Mwvv7668EeOnRosO08DBo0KJRxcNKSJUs6lTdiXeoyEgu64p7x97///dzrVC88X5zVp2akxlTPWAghhCgYPYyFEEKIgmk5feR73/seAOCCCy4IZS+99FKwf/rTn3b5+7vuuivYo0ePDvYLL7wAAJg1a1YjqlkKWGpj3nzzTQDAs88+m2d1uo0F17F0xLIsS+ytxLXXXhvsr33ta8HmuZOW0pWHVzhohVOQmp9uueWWxle2F5AKxJk0aRIA4JJLLgllvMbxggULgm1y7COPPBLKuP1xMNewYcMAADfeeGMPal1eWJK24RI+/tSQn127PE85FSAa+y7fB9j39p2UxMx1s7rztcKfNyOgTj1jIYQQomD0MBZCCCEKxuU5f8059zqAdwBsrvbdXsoeaPyx7eO937M7P6z4ew2aU6+y0Ohj67a/AbXxbtLTNi5/14fuKV1TyD0l14cxADjnFnZYvL1lKOuxlbVejaCMx1bGOjWKMh5bGevUKMp6bGWtVyMo6tgkUwshhBAFo4exEEIIUTBFPIynFLDPvCjrsZW1Xo2gjMdWxjo1ijIeWxnr1CjKemxlrVcjKOTYch8zFkIIIUQWydRCCCFEweT6MHbOneqce945t8o5NznPfTca59wA59xs59xy59wy59zllfI+zrkZzrmVlf93q7atJtZR/s63jvJ3/vWUz/Oto/zdLLz3ufwDsB2A1QAGAdgBwDMAhue1/yYcTxuAURV7VwAvABgO4HoAkyvlkwF8r6D6yd/yd8v6Wz6Xv1vN33n2jEcDWOW9f9F7/x6AuwCMz3H/DcV7v8F7v6hivw1gBYD+2HpMUytfmwrg88XUUP7OGfk7f+TzfJG/m0ieD+P+ANbS3+sqZb0e59xAAIcCmA+gn/feFvl9DUC/gqolf+eL/J0/8nm+yN9NRAFcPcQ5twuAewBc4b1/iz/zW3UOhas3EPk7X+Tv/JHP86Us/s7zYbwewAD6e+9KWa/FObc9tp7EO7z3v6wUb3TOtVU+bwOwqaDqyd/5In/nj3yeL/J3E8nzYbwAwBDn3L7OuR0AnAPgvhz331Dc1kUxbwWwwnt/A310H4AJFXsCgGl5162C/J0v8nf+yOf5In83k5yj18Zha8TaagBX57nvJhzL0dgqXywBsLjybxyA3QHMBLASwMMA+hRYR/lb/m5Zf8vn8ncr+VsZuIQQQoiCUQCXEEIIUTB6GAshhBAFo7pS40QAAAAzSURBVIexEEIIUTB6GAshhBAFo4exEEIIUTB6GAshhBAFo4exEEIIUTB6GAshhBAF8/8BhsAz9uQ+zu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def render_random_images(data, num_samples):\n",
    "    cols = 5\n",
    "    rows = math.ceil(num_samples/cols)\n",
    "    idxs = np.random.choice(len(data), num_samples)\n",
    "    f, ax = plt.subplots(rows, cols)\n",
    "    f.set_size_inches(8, 4)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        x = i//cols\n",
    "        y = i%cols\n",
    "        if rows > 1:\n",
    "            ax[x, y].imshow(data[idx].reshape(data.shape[1], data.shape[2]), cmap='gray')\n",
    "        else:\n",
    "            ax[i].imshow(data[idx].reshape(data.shape[1], data.shape[2]), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "render_random_images(x_train_indata, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ff1a5ec1cd878fa152e82e613ecc19f3906e740"
   },
   "source": [
    "### Check for duplicates/overlaps\n",
    "Does the training data and test data contain duplicates or do they overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9f84b47721e8d2a4d766d43d11c7624fa85c7416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in combined dataset: False\n"
     ]
    }
   ],
   "source": [
    "def has_duplicates(a):\n",
    "    ah = [hashlib.sha1(x).hexdigest() for x in a]\n",
    "    _, counts = np.unique(ah, return_counts=True)    \n",
    "    if len(collections.Counter(counts).keys()) > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(\"Duplicates in combined dataset:\", has_duplicates(np.concatenate((x_train_indata, x_test_indata))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08f16a2c3fcca54436fe931354932d20143b6770"
   },
   "source": [
    "### Check for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4ca41c7b29757768c905b659b5904fd9d77f3027"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(y_train_indata, bins=range(0,11), label=\"training\")\n",
    "_ = plt.hist(y_test_indata, bins=range(0,11), label=\"test\")\n",
    "\n",
    "plt.xlabel('Class index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of frequency per class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9fc21e891d972f24a516f13983bd1badcf94de8"
   },
   "source": [
    "The classes are equally common. This was expected, but still good to check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "372299f06231a5fb5c0691e5e65248a9573cbc89"
   },
   "source": [
    "## Transform data / split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "76a455646a61c4cfc070f40a811990dafbb5c2d0"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# Split the training data into training (50K samples) and validation (10K samples)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "    x_train_indata, \n",
    "    y_train_indata, \n",
    "    test_size=0.16666, \n",
    "    random_state=42)\n",
    "\n",
    "# Add one dimension because the CNN layers expect n feature maps (color channels)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0], x_validation.shape[1], x_validation.shape[2], 1)\n",
    "y_validation = to_categorical(y_validation, num_classes=num_classes)\n",
    "x_test = x_test_indata.reshape(x_test_indata.shape[0], x_test_indata.shape[1], x_test_indata.shape[2], 1)\n",
    "y_test = to_categorical(y_test_indata, num_classes=num_classes)\n",
    "\n",
    "# zero-center and normalize pixels\n",
    "# preprocess_input is as simple as this:\n",
    "# x /= 255.\n",
    "# x -= 0.5\n",
    "# x *= 2.\n",
    "x_train = inception_resnet_v2.preprocess_input(x_train)\n",
    "x_validation = inception_resnet_v2.preprocess_input(x_validation)\n",
    "x_test = inception_resnet_v2.preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bd33e68ccf9d47d7acc3ba76b6f9133098aa152f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-verify that the images look correct\n",
    "render_random_images(x_train, 5)\n",
    "render_random_images(x_validation, 5)\n",
    "render_random_images(x_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf47e7f8ee10ef7cdaf989e942362ec46f6980ee"
   },
   "source": [
    "### Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval1d(model):\n",
    "    score = model.evaluate(np.reshape(x_validation, (x_validation.shape[0], 784)), y_validation, verbose=0)\n",
    "    for i, _ in enumerate(score):\n",
    "        print(model.metrics_names[i], score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, eval_test=False):\n",
    "    if eval_test:\n",
    "        print(\"Evaluating on TEST data\")\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    else:\n",
    "        print(\"Evaluating on validation data\")\n",
    "        score = model.evaluate(x_validation, y_validation, verbose=0)\n",
    "    for i, _ in enumerate(score):\n",
    "        print(model.metrics_names[i], score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear model with only one layer\n",
    "def model0(learning_rate=0.01, momentum=0.9, decay=1e-6):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_classes, activation='softmax',input_shape=(784,)))\n",
    "    model.custom_name = 'model0'\n",
    "    sgd = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay, nesterov=False)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Compiled {} with lr={} momentum={}, decay={}\".format(model.custom_name, learning_rate, momentum, decay))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model with only one convolutional layer\n",
    "def model1(learning_rate=0.01, momentum=0.9, decay=1e-6):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(1,1), input_shape=(28,28,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.custom_name = 'model1'\n",
    "    sgd = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay, nesterov=False)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Compiled {} with lr={} momentum={}, decay={}\".format(model.custom_name, learning_rate, momentum, decay))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper model with 3 convolutional layers, max-pooling and dropout\n",
    "def model2(learning_rate=0.01, momentum=0.9, decay=1e-6):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "    model.add(Conv2D(16, kernel_size=(2,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "    model.add(Conv2D(16, kernel_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.custom_name = 'model2'\n",
    "    \n",
    "    sgd = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay, nesterov=False)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Compiled {} with lr={} momentum={}, decay={}\".format(model.custom_name, learning_rate, momentum, decay))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9c2088b5b13e0b100f477478ca62477e1984287b"
   },
   "outputs": [],
   "source": [
    "# Train the three models defined above\n",
    "def run(model, epochs, batch_size, eval_test=False):\n",
    "    model.summary()\n",
    "    run_name = datetime.datetime.now().strftime(\"_%Y-%m-%dT%H_%M_%S\")\n",
    "    tb_cb = tf.keras.callbacks.TensorBoard(log_dir=\"./graph/\" + model.custom_name + run_name,\n",
    "                                           histogram_freq=0,\n",
    "                                           write_graph=True,\n",
    "                                           write_images=False,\n",
    "                                           write_grads=False)\n",
    "    if model.custom_name == 'model0':\n",
    "        model.fit(np.reshape(x_train, (x_train.shape[0], 784)),\n",
    "                  y_train,\n",
    "                  validation_data=(np.reshape(x_validation, (x_validation.shape[0], 784)), y_validation),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[tb_cb],\n",
    "                  verbose=2)\n",
    "        eval1d(model)\n",
    "    else:\n",
    "        model.fit(x_train, \n",
    "                  y_train,\n",
    "                  validation_data=(x_validation, y_validation),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[tb_cb],\n",
    "                  verbose=1)\n",
    "        eval(model, eval_test=eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled model0 with lr=0.01 momentum=0.9, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 0.5780 - acc: 0.8011 - val_loss: 0.5421 - val_acc: 0.8155\n",
      "Epoch 2/30\n",
      " - 4s - loss: 0.5037 - acc: 0.8295 - val_loss: 0.5029 - val_acc: 0.8302\n",
      "Epoch 3/30\n",
      " - 4s - loss: 0.4967 - acc: 0.8330 - val_loss: 0.5660 - val_acc: 0.8140\n",
      "Epoch 4/30\n",
      " - 4s - loss: 0.4713 - acc: 0.8408 - val_loss: 0.4802 - val_acc: 0.8377\n",
      "Epoch 5/30\n",
      " - 4s - loss: 0.4704 - acc: 0.8420 - val_loss: 0.5241 - val_acc: 0.8303\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.4627 - acc: 0.8403 - val_loss: 0.4873 - val_acc: 0.8357\n",
      "Epoch 7/30\n",
      " - 4s - loss: 0.4536 - acc: 0.8446 - val_loss: 0.5210 - val_acc: 0.8231\n",
      "Epoch 8/30\n",
      " - 4s - loss: 0.4542 - acc: 0.8442 - val_loss: 0.4811 - val_acc: 0.8371\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.4535 - acc: 0.8459 - val_loss: 0.4830 - val_acc: 0.8293\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.4434 - acc: 0.8487 - val_loss: 0.4903 - val_acc: 0.8418\n",
      "Epoch 11/30\n",
      " - 4s - loss: 0.4459 - acc: 0.8464 - val_loss: 0.5029 - val_acc: 0.8302\n",
      "Epoch 12/30\n",
      " - 4s - loss: 0.4432 - acc: 0.8477 - val_loss: 0.5360 - val_acc: 0.8284\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.4470 - acc: 0.8471 - val_loss: 0.5346 - val_acc: 0.8187\n",
      "Epoch 14/30\n",
      " - 4s - loss: 0.4386 - acc: 0.8508 - val_loss: 0.5141 - val_acc: 0.8258\n",
      "Epoch 15/30\n",
      " - 4s - loss: 0.4373 - acc: 0.8485 - val_loss: 0.5649 - val_acc: 0.8214\n",
      "Epoch 16/30\n",
      " - 4s - loss: 0.4402 - acc: 0.8492 - val_loss: 0.5298 - val_acc: 0.8195\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.4463 - acc: 0.8473 - val_loss: 0.4736 - val_acc: 0.8427\n",
      "Epoch 18/30\n",
      " - 4s - loss: 0.4346 - acc: 0.8506 - val_loss: 0.5221 - val_acc: 0.8234\n",
      "Epoch 19/30\n",
      " - 4s - loss: 0.4332 - acc: 0.8516 - val_loss: 0.4854 - val_acc: 0.8365\n",
      "Epoch 20/30\n",
      " - 4s - loss: 0.4358 - acc: 0.8502 - val_loss: 0.4922 - val_acc: 0.8438\n",
      "Epoch 21/30\n",
      " - 4s - loss: 0.4386 - acc: 0.8499 - val_loss: 0.4746 - val_acc: 0.8458\n",
      "Epoch 22/30\n",
      " - 4s - loss: 0.4377 - acc: 0.8515 - val_loss: 0.5659 - val_acc: 0.8169\n",
      "Epoch 23/30\n",
      " - 4s - loss: 0.4333 - acc: 0.8525 - val_loss: 0.5141 - val_acc: 0.8339\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.4290 - acc: 0.8533 - val_loss: 0.5311 - val_acc: 0.8271\n",
      "Epoch 25/30\n",
      " - 4s - loss: 0.4298 - acc: 0.8519 - val_loss: 0.5066 - val_acc: 0.8306\n",
      "Epoch 26/30\n",
      " - 4s - loss: 0.4258 - acc: 0.8529 - val_loss: 0.5177 - val_acc: 0.8318\n",
      "Epoch 27/30\n",
      " - 4s - loss: 0.4270 - acc: 0.8527 - val_loss: 0.5013 - val_acc: 0.8345\n",
      "Epoch 28/30\n",
      " - 4s - loss: 0.4289 - acc: 0.8522 - val_loss: 0.5302 - val_acc: 0.8281\n",
      "Epoch 29/30\n",
      " - 4s - loss: 0.4248 - acc: 0.8537 - val_loss: 0.5112 - val_acc: 0.8293\n",
      "Epoch 30/30\n",
      " - 4s - loss: 0.4267 - acc: 0.8540 - val_loss: 0.5331 - val_acc: 0.8370\n",
      "loss 0.5330692998886108\n",
      "acc 0.837\n",
      "Compiled model1 with lr=0.01 momentum=0.9, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 250,954\n",
      "Trainable params: 250,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.7036 - acc: 0.7994 - val_loss: 0.6206 - val_acc: 0.8187\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.6547 - acc: 0.8080 - val_loss: 0.6108 - val_acc: 0.8211\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.6535 - acc: 0.8076 - val_loss: 0.6612 - val_acc: 0.8004\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6577 - acc: 0.8082 - val_loss: 0.6308 - val_acc: 0.8123\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6622 - acc: 0.8071 - val_loss: 0.6412 - val_acc: 0.8205\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6543 - acc: 0.8095 - val_loss: 0.6195 - val_acc: 0.8184\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6540 - acc: 0.8072 - val_loss: 0.6080 - val_acc: 0.8310\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6526 - acc: 0.8077 - val_loss: 0.6953 - val_acc: 0.8028\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6558 - acc: 0.8079 - val_loss: 0.6595 - val_acc: 0.7952\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6520 - acc: 0.8082 - val_loss: 0.6739 - val_acc: 0.8008\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6519 - acc: 0.8073 - val_loss: 0.6145 - val_acc: 0.8231\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6488 - acc: 0.8101 - val_loss: 0.6814 - val_acc: 0.7953\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.6510 - acc: 0.8075 - val_loss: 0.6348 - val_acc: 0.8138\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6596 - acc: 0.8082 - val_loss: 0.6202 - val_acc: 0.8260\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6488 - acc: 0.8099 - val_loss: 0.6452 - val_acc: 0.8041\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6502 - acc: 0.8077 - val_loss: 0.6440 - val_acc: 0.8168\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6479 - acc: 0.8109 - val_loss: 0.6110 - val_acc: 0.8279\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6538 - acc: 0.8092 - val_loss: 0.7702 - val_acc: 0.7844\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6508 - acc: 0.8104 - val_loss: 0.6519 - val_acc: 0.8118\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6517 - acc: 0.8088 - val_loss: 0.7600 - val_acc: 0.7864\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6516 - acc: 0.8090 - val_loss: 0.6834 - val_acc: 0.8010\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6496 - acc: 0.8097 - val_loss: 0.7162 - val_acc: 0.7967\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.6525 - acc: 0.8091 - val_loss: 0.6591 - val_acc: 0.8081\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6487 - acc: 0.8109 - val_loss: 0.6897 - val_acc: 0.7935\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.6479 - acc: 0.8106 - val_loss: 0.6347 - val_acc: 0.8187\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6473 - acc: 0.8109 - val_loss: 0.6457 - val_acc: 0.8100\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6428 - acc: 0.8116 - val_loss: 0.6133 - val_acc: 0.8192\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6527 - acc: 0.8075 - val_loss: 0.6739 - val_acc: 0.8131\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6530 - acc: 0.8090 - val_loss: 0.6552 - val_acc: 0.8053\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6432 - acc: 0.8104 - val_loss: 0.7239 - val_acc: 0.7657\n",
      "Evaluating on validation data\n",
      "loss 0.7239260896205902\n",
      "acc 0.7657\n",
      "Compiled model2 with lr=0.01 momentum=0.9, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 16)        2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 16)          1040      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 56,042\n",
      "Trainable params: 56,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.6160 - acc: 0.8038 - val_loss: 0.4716 - val_acc: 0.8512\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.4460 - acc: 0.8573 - val_loss: 0.3988 - val_acc: 0.8712\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.4108 - acc: 0.8707 - val_loss: 0.3736 - val_acc: 0.8770\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3870 - acc: 0.8780 - val_loss: 0.3656 - val_acc: 0.8841\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3671 - acc: 0.8839 - val_loss: 0.3701 - val_acc: 0.8861\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3579 - acc: 0.8879 - val_loss: 0.3443 - val_acc: 0.8938\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3481 - acc: 0.8915 - val_loss: 0.3342 - val_acc: 0.8924\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3348 - acc: 0.8955 - val_loss: 0.3588 - val_acc: 0.8856\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3285 - acc: 0.8979 - val_loss: 0.3548 - val_acc: 0.8869\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3235 - acc: 0.8994 - val_loss: 0.3537 - val_acc: 0.8905\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3117 - acc: 0.9029 - val_loss: 0.3478 - val_acc: 0.8923\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.3071 - acc: 0.9044 - val_loss: 0.3340 - val_acc: 0.8977\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3016 - acc: 0.9078 - val_loss: 0.3306 - val_acc: 0.8975\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2982 - acc: 0.9080 - val_loss: 0.3389 - val_acc: 0.8968\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.2932 - acc: 0.9118 - val_loss: 0.3378 - val_acc: 0.8972\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2856 - acc: 0.9134 - val_loss: 0.3461 - val_acc: 0.8964\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2848 - acc: 0.9136 - val_loss: 0.3470 - val_acc: 0.8992\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2823 - acc: 0.9149 - val_loss: 0.3450 - val_acc: 0.8952\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2794 - acc: 0.9161 - val_loss: 0.3437 - val_acc: 0.8976\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.2698 - acc: 0.9183 - val_loss: 0.3460 - val_acc: 0.8980\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2688 - acc: 0.9193 - val_loss: 0.3698 - val_acc: 0.8949\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2678 - acc: 0.9199 - val_loss: 0.3555 - val_acc: 0.9020\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2631 - acc: 0.9235 - val_loss: 0.3697 - val_acc: 0.9018\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2591 - acc: 0.9248 - val_loss: 0.3447 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.2601 - acc: 0.9246 - val_loss: 0.3804 - val_acc: 0.8982\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2622 - acc: 0.9236 - val_loss: 0.3679 - val_acc: 0.9019\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2561 - acc: 0.9249 - val_loss: 0.3542 - val_acc: 0.8987\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2481 - acc: 0.9277 - val_loss: 0.3794 - val_acc: 0.8926\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2457 - acc: 0.9291 - val_loss: 0.4142 - val_acc: 0.8914\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2465 - acc: 0.9291 - val_loss: 0.3861 - val_acc: 0.8955\n",
      "Evaluating on validation data\n",
      "loss 0.386075016438961\n",
      "acc 0.8955\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # Training might crash otherwise\n",
    "run(model0(), epochs=30, batch_size=32)\n",
    "tf.keras.backend.clear_session()\n",
    "run(model1(), epochs=30, batch_size=32)\n",
    "tf.keras.backend.clear_session()\n",
    "run(model2(), epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data so that it is compatible with Inception-ResNet-v2.\n",
    "# Then extract features by running the datasets through Inception-ResNet-v2.\n",
    "# Finally, cache the files locally so that we don't need to preprocess multiple times.\n",
    "# This step requires 15-20GB RAM so it could take some time on a low memory machine or create an Out of memory error.\n",
    "def prepare_img_data_for_inception():\n",
    "    print('generating...')\n",
    "    x_train_zoom = scipy.ndimage.zoom(x_train, (1,3,3,1), order=0)\n",
    "    x_validation_zoom = scipy.ndimage.zoom(x_validation, (1,3,3,1), order=0)\n",
    "    x_test_zoom = scipy.ndimage.zoom(x_test, (1,3,3,1), order=0)\n",
    "    x_train_inc = np.repeat(x_train_zoom, 3, axis=3)\n",
    "    x_validation_inc = np.repeat(x_validation_zoom, 3, axis=3)\n",
    "    x_train_inc = None\n",
    "    x_validation_inc = None\n",
    "    x_test_inc = np.repeat(x_test_zoom, 3, axis=3)\n",
    "    print('done generating')\n",
    "    return x_train_inc, x_validation_inc, x_test_inc\n",
    "\n",
    "def preprocess_inception(x_train_inc, x_validation_inc, x_test_inc):\n",
    "    print(\"creating inception model (this takes a while)...\")\n",
    "    inception = inception_resnet_v2.InceptionResNetV2(\n",
    "                                                    include_top=False,\n",
    "                                                    weights='imagenet',\n",
    "                                                    input_tensor=None,\n",
    "                                                    input_shape=(84,84,3),\n",
    "                                                    pooling=None)\n",
    "    print(\"extracting features from training images...\")\n",
    "    features_train = inception.predict(x_train_inc, verbose=1)\n",
    "    print(\"extracting features from validation images...\")\n",
    "    features_validation = inception.predict(x_validation_inc, verbose=1)\n",
    "    print(\"extracting features from test images...\")\n",
    "    features_test = inception.predict(x_test_inc, verbose=1)\n",
    "    print(\"done extracting\")\n",
    "    # reshape, because predict() returns an array with shape (\"num samples\", 1, 1, \"output layer size\")\n",
    "    features_train = np.reshape(features_train, (features_train.shape[0], features_train.shape[3]))\n",
    "    features_validation = np.reshape(features_validation, (features_validation.shape[0], features_validation.shape[3]))\n",
    "    features_train = None\n",
    "    features_validation = None\n",
    "    features_test = np.reshape(features_test, (features_test.shape[0], features_test.shape[3]))\n",
    "    return features_train, features_validation, features_test\n",
    "\n",
    "def preprocess_or_load():\n",
    "    feature_file_name1 = 'inception_features_train.npy'\n",
    "    feature_file_name2 = 'inception_features_validation.npy'\n",
    "    feature_file_name3 = 'inception_features_test.npy'\n",
    "    if not (os.path.isfile(feature_file_name1) and os.path.isfile(feature_file_name2) and os.path.isfile(feature_file_name3)):\n",
    "        x_train_inc, x_validation_inc, x_test_inc = prepare_img_data_for_inception()\n",
    "        features_train, features_validation, features_test = preprocess_inception(x_train_inc, x_validation_inc, x_test_inc)\n",
    "        np.save(feature_file_name1, features_train)\n",
    "        np.save(feature_file_name2, features_validation)\n",
    "        np.save(feature_file_name3, features_test)\n",
    "    else:\n",
    "        features_train = np.load(feature_file_name1)\n",
    "        features_validation = np.load(feature_file_name2)\n",
    "        features_test = np.load(feature_file_name3)\n",
    "    return features_train, features_validation, features_test\n",
    "    \n",
    "features_train, features_validation, features_test = preprocess_or_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2-layer fully connected network as the classifier on top of inceptionnet's features.\n",
    "def model3(learning_rate=0.01, momentum=0.9, decay=1e-6):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(1536,))) # inception net yeilds 1536 features\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.custom_name = \"model3\"\n",
    "    sgd = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay, nesterov=False)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Compiled {} with lr={} momentum={}, decay={}\".format(model.custom_name, learning_rate, momentum, decay))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the \"transfer learning\" model\n",
    "def run_model3(model, epochs, batch_size, eval_test=False):\n",
    "    model.summary()\n",
    "    run_name = datetime.datetime.now().strftime(\"_%Y-%m-%dT%H_%M_%S\")\n",
    "    tb_cb = tf.keras.callbacks.TensorBoard(log_dir=\"./graph/\" + model.custom_name + run_name,\n",
    "                                           histogram_freq=0,\n",
    "                                           write_graph=True,\n",
    "                                           write_images=False,\n",
    "                                           write_grads=False)\n",
    "    print(\"epochs\", epochs)\n",
    "    print(\"batch_size\", batch_size)\n",
    "    model.fit(features_train,\n",
    "              y_train,\n",
    "              validation_data=(features_validation, y_validation),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=[tb_cb],\n",
    "              verbose=1)\n",
    "\n",
    "    # evaluate model\n",
    "    if eval_test:\n",
    "        score = model.evaluate(features_test, y_test, verbose=1)\n",
    "        print(\"Evaluating on TEST data\")\n",
    "    else:\n",
    "        score = model.evaluate(features_validation, y_validation, verbose=1)\n",
    "        print(\"Evaluating on validation data\")\n",
    "    for i, _ in enumerate(score):\n",
    "        print(model.metrics_names[i], score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled model3 with lr=0.01 momentum=0.9, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 205,642\n",
      "Trainable params: 205,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "epochs 30\n",
      "batch_size 32\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.7363 - acc: 0.7386 - val_loss: 0.5562 - val_acc: 0.7961\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.5519 - acc: 0.8025 - val_loss: 0.4927 - val_acc: 0.8161\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.5114 - acc: 0.8174 - val_loss: 0.4668 - val_acc: 0.8320\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.4768 - acc: 0.8284 - val_loss: 0.4500 - val_acc: 0.8364\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.4536 - acc: 0.8371 - val_loss: 0.4463 - val_acc: 0.8423\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.4367 - acc: 0.8407 - val_loss: 0.4463 - val_acc: 0.8413\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.4170 - acc: 0.8478 - val_loss: 0.4242 - val_acc: 0.8429\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.4096 - acc: 0.8529 - val_loss: 0.4299 - val_acc: 0.8392\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3981 - acc: 0.8558 - val_loss: 0.4152 - val_acc: 0.8505\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.3912 - acc: 0.8551 - val_loss: 0.4229 - val_acc: 0.8488\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3785 - acc: 0.8626 - val_loss: 0.4115 - val_acc: 0.8590\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3758 - acc: 0.8615 - val_loss: 0.4153 - val_acc: 0.8519\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.3588 - acc: 0.8681 - val_loss: 0.4104 - val_acc: 0.8559\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.3564 - acc: 0.8680 - val_loss: 0.4053 - val_acc: 0.8597\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.3553 - acc: 0.8700 - val_loss: 0.4013 - val_acc: 0.8591\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.3475 - acc: 0.8722 - val_loss: 0.4005 - val_acc: 0.8624\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3398 - acc: 0.8739 - val_loss: 0.4318 - val_acc: 0.8515\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.3342 - acc: 0.8772 - val_loss: 0.4003 - val_acc: 0.8624\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3323 - acc: 0.8769 - val_loss: 0.4383 - val_acc: 0.8458\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3269 - acc: 0.8811 - val_loss: 0.4009 - val_acc: 0.8627\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3154 - acc: 0.8835 - val_loss: 0.4116 - val_acc: 0.8559\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3176 - acc: 0.8829 - val_loss: 0.4328 - val_acc: 0.8555\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3124 - acc: 0.8834 - val_loss: 0.4051 - val_acc: 0.8654\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3080 - acc: 0.8872 - val_loss: 0.4093 - val_acc: 0.8631\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3060 - acc: 0.8872 - val_loss: 0.4151 - val_acc: 0.8600\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.2982 - acc: 0.8906 - val_loss: 0.4168 - val_acc: 0.8602\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2974 - acc: 0.8899 - val_loss: 0.4166 - val_acc: 0.8627\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.2998 - acc: 0.8891 - val_loss: 0.4335 - val_acc: 0.8591\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2926 - acc: 0.8926 - val_loss: 0.4187 - val_acc: 0.8680\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2902 - acc: 0.8933 - val_loss: 0.4284 - val_acc: 0.8575\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "Evaluating on validation data\n",
      "loss 0.4283570661187172\n",
      "acc 0.8575\n"
     ]
    }
   ],
   "source": [
    "run_model3(model3(), epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two grid searches to find better epoch/batch_size and learning_rate/momentum parameters.\n",
    "# The first run takes ~2h30m on a K80 GPU and the second one \n",
    "# Uncomment below to activate\n",
    "\n",
    "# Support TensorBoard callbacks when running through the KerasClassifer wrapper\n",
    "# KerasClassifierTB adapted from https://stackoverflow.com/questions/45454905/how-to-use-keras-tensorboard-callback-for-grid-search\n",
    "class KerasClassifierTB(KerasClassifier):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasClassifierTB, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def fit(self, x, y, log_dir=None, **kwargs):\n",
    "        cbs = None\n",
    "        if log_dir is not None:\n",
    "            # Make sure the base log directory exists\n",
    "            try:\n",
    "                os.makedirs(log_dir)\n",
    "            except OSError:\n",
    "                pass\n",
    "            params = self.get_params()\n",
    "            params.pop(\"build_fn\", None)\n",
    "            conf = \",\".join(\"{}={}\".format(k, params[k])\n",
    "                            for k in sorted(params))\n",
    "            conf_dir_base = os.path.join(log_dir, conf)\n",
    "            # Find a new directory to place the logs\n",
    "            try:\n",
    "                d_string = datetime.datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")\n",
    "                conf_dir = \"{}_{}\".format(conf_dir_base, d_string)\n",
    "                os.makedirs(conf_dir)\n",
    "            except OSError:\n",
    "                pass\n",
    "            cbs = [TensorBoard(log_dir=conf_dir, histogram_freq=0,\n",
    "                               write_graph=False, write_images=False)]\n",
    "        super(KerasClassifierTB, self).fit(x, y, callbacks=cbs, **kwargs)\n",
    "\n",
    "# Grid search code adapted from https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "def run_grid_search_e_bs(model_name, model_fn, param_grid, x, y):\n",
    "    model_wrapper = KerasClassifierTB(build_fn=model_fn, verbose=2)\n",
    "    grid = GridSearchCV(estimator=model_wrapper, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "    grid_result = grid.fit(x, y, log_dir=\"./graph/{}\".format(model_name))\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "        \n",
    "def search_e_bs():\n",
    "    np.random.seed(7) # for reproducibility\n",
    "    param_grid = {\n",
    "        \"batch_size\": [16, 32, 128, 512, 2048],\n",
    "        \"epochs\": [10, 30, 50]\n",
    "    }\n",
    "    run_grid_search_e_bs(\"model2\", model2, param_grid, x_train, y_train)\n",
    "    run_grid_search_e_bs(\"model3\", model3, param_grid, features_train, y_train)\n",
    "    np.random.seed(None)\n",
    "# Uncomment to run\n",
    "# search_e_bs()\n",
    "\n",
    "def run_grid_search_lr_m(model_name, model_fn, param_grid, x, y):\n",
    "    model_wrapper = KerasClassifierTB(build_fn=model_fn, verbose=2, batch_size=128, epochs=50)\n",
    "    grid = GridSearchCV(estimator=model_wrapper, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "    grid_result = grid.fit(x, y, log_dir=\"./graph/{}\".format(model_name))\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "def search_lr_m():\n",
    "    np.random.seed(7) # for reproducibility\n",
    "    param_grid = {\n",
    "        \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        \"momentum\": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "    }\n",
    "    run_grid_search_lr_m(\"model2\", model2, param_grid, x_train, y_train)\n",
    "    run_grid_search_lr_m(\"model3\", model3, param_grid, features_train, y_train)\n",
    "    np.random.seed(None)\n",
    "# Uncomment to run\n",
    "# search_lr_m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled model2 with lr=0.01 momentum=0.8, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 16)        2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 16)          1040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 56,042\n",
      "Trainable params: 56,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.8648 - acc: 0.7399 - val_loss: 0.5832 - val_acc: 0.8293\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.5601 - acc: 0.8268 - val_loss: 0.4808 - val_acc: 0.8522\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.4822 - acc: 0.8444 - val_loss: 0.4306 - val_acc: 0.8624\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.4447 - acc: 0.8534 - val_loss: 0.4032 - val_acc: 0.8678\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.4191 - acc: 0.8613 - val_loss: 0.3913 - val_acc: 0.8721\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.4000 - acc: 0.8659 - val_loss: 0.3891 - val_acc: 0.8662\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3873 - acc: 0.8693 - val_loss: 0.3793 - val_acc: 0.8710\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3791 - acc: 0.8729 - val_loss: 0.3558 - val_acc: 0.8824\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3684 - acc: 0.8766 - val_loss: 0.3521 - val_acc: 0.8827\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3594 - acc: 0.8790 - val_loss: 0.3479 - val_acc: 0.8851\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3512 - acc: 0.8824 - val_loss: 0.3369 - val_acc: 0.8893\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3438 - acc: 0.8849 - val_loss: 0.3459 - val_acc: 0.8859\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3387 - acc: 0.8865 - val_loss: 0.3346 - val_acc: 0.8875\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3339 - acc: 0.8886 - val_loss: 0.3249 - val_acc: 0.8932\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3262 - acc: 0.8897 - val_loss: 0.3283 - val_acc: 0.8914\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3217 - acc: 0.8916 - val_loss: 0.3249 - val_acc: 0.8930\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3192 - acc: 0.8938 - val_loss: 0.3281 - val_acc: 0.8918\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3101 - acc: 0.8959 - val_loss: 0.3267 - val_acc: 0.8926\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3087 - acc: 0.8968 - val_loss: 0.3084 - val_acc: 0.8990\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3060 - acc: 0.8981 - val_loss: 0.3082 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3004 - acc: 0.8985 - val_loss: 0.3160 - val_acc: 0.8946\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2969 - acc: 0.9008 - val_loss: 0.3029 - val_acc: 0.9010\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2940 - acc: 0.9023 - val_loss: 0.3101 - val_acc: 0.8976\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2904 - acc: 0.9023 - val_loss: 0.3033 - val_acc: 0.8985\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2885 - acc: 0.9040 - val_loss: 0.3046 - val_acc: 0.8976\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2847 - acc: 0.9039 - val_loss: 0.3173 - val_acc: 0.8953\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2833 - acc: 0.9056 - val_loss: 0.3089 - val_acc: 0.8975\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2806 - acc: 0.9069 - val_loss: 0.2992 - val_acc: 0.9030\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2770 - acc: 0.9066 - val_loss: 0.3022 - val_acc: 0.9022\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2724 - acc: 0.9092 - val_loss: 0.3092 - val_acc: 0.9025\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2711 - acc: 0.9093 - val_loss: 0.3141 - val_acc: 0.8936\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2686 - acc: 0.9103 - val_loss: 0.2965 - val_acc: 0.9031\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2677 - acc: 0.9108 - val_loss: 0.3008 - val_acc: 0.9042\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2660 - acc: 0.9093 - val_loss: 0.3126 - val_acc: 0.8980\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2625 - acc: 0.9121 - val_loss: 0.3023 - val_acc: 0.8983\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2596 - acc: 0.9147 - val_loss: 0.3056 - val_acc: 0.9024\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2578 - acc: 0.9148 - val_loss: 0.2974 - val_acc: 0.9010\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2562 - acc: 0.9153 - val_loss: 0.2934 - val_acc: 0.9054\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2544 - acc: 0.9156 - val_loss: 0.2969 - val_acc: 0.9026\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2537 - acc: 0.9148 - val_loss: 0.2940 - val_acc: 0.9047\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2500 - acc: 0.9172 - val_loss: 0.2973 - val_acc: 0.9009\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2488 - acc: 0.9170 - val_loss: 0.3090 - val_acc: 0.9003\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2438 - acc: 0.9182 - val_loss: 0.2923 - val_acc: 0.9052\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2453 - acc: 0.9189 - val_loss: 0.2976 - val_acc: 0.9026\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2427 - acc: 0.9195 - val_loss: 0.3010 - val_acc: 0.8981\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2428 - acc: 0.9200 - val_loss: 0.2863 - val_acc: 0.9060\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2366 - acc: 0.9226 - val_loss: 0.2921 - val_acc: 0.9070\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2373 - acc: 0.9216 - val_loss: 0.2856 - val_acc: 0.9071\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2314 - acc: 0.9248 - val_loss: 0.2905 - val_acc: 0.9076\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2331 - acc: 0.9235 - val_loss: 0.2925 - val_acc: 0.9066\n",
      "Evaluating on TEST data\n",
      "loss 0.30655471302270887\n",
      "acc 0.9013\n",
      "Compiled model3 with lr=0.001 momentum=0.9, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 205,642\n",
      "Trainable params: 205,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "epochs 50\n",
      "batch_size 128\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.0496 - acc: 0.6477 - val_loss: 0.6512 - val_acc: 0.7804\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.6692 - acc: 0.7687 - val_loss: 0.5667 - val_acc: 0.8021\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.5875 - acc: 0.7956 - val_loss: 0.5234 - val_acc: 0.8139\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.5404 - acc: 0.8087 - val_loss: 0.4923 - val_acc: 0.8271\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.5098 - acc: 0.8198 - val_loss: 0.4808 - val_acc: 0.8266\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4822 - acc: 0.8299 - val_loss: 0.4551 - val_acc: 0.8399\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4616 - acc: 0.8365 - val_loss: 0.4485 - val_acc: 0.8426\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4470 - acc: 0.8411 - val_loss: 0.4442 - val_acc: 0.8388\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4344 - acc: 0.8444 - val_loss: 0.4316 - val_acc: 0.8437\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4209 - acc: 0.8489 - val_loss: 0.4220 - val_acc: 0.8487\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4123 - acc: 0.8520 - val_loss: 0.4170 - val_acc: 0.8506\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3995 - acc: 0.8568 - val_loss: 0.4156 - val_acc: 0.8532\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3906 - acc: 0.8577 - val_loss: 0.4172 - val_acc: 0.8534\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3851 - acc: 0.8603 - val_loss: 0.4093 - val_acc: 0.8536\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3749 - acc: 0.8650 - val_loss: 0.4063 - val_acc: 0.8563\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3688 - acc: 0.8649 - val_loss: 0.4089 - val_acc: 0.8566\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3637 - acc: 0.8683 - val_loss: 0.3998 - val_acc: 0.8592\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3547 - acc: 0.8709 - val_loss: 0.3978 - val_acc: 0.8587\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3504 - acc: 0.8714 - val_loss: 0.3951 - val_acc: 0.8582\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3440 - acc: 0.8752 - val_loss: 0.3941 - val_acc: 0.8569\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3372 - acc: 0.8771 - val_loss: 0.3908 - val_acc: 0.8596\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3328 - acc: 0.8795 - val_loss: 0.3891 - val_acc: 0.8602\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3284 - acc: 0.8791 - val_loss: 0.3933 - val_acc: 0.8577\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3224 - acc: 0.8812 - val_loss: 0.3859 - val_acc: 0.8615\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3184 - acc: 0.8845 - val_loss: 0.3809 - val_acc: 0.8638\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3123 - acc: 0.8855 - val_loss: 0.3809 - val_acc: 0.8633\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3081 - acc: 0.8870 - val_loss: 0.3817 - val_acc: 0.8649\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3024 - acc: 0.8882 - val_loss: 0.3883 - val_acc: 0.8634\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3019 - acc: 0.8887 - val_loss: 0.3814 - val_acc: 0.8643\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2982 - acc: 0.8914 - val_loss: 0.3830 - val_acc: 0.8661\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.2944 - acc: 0.8918 - val_loss: 0.3783 - val_acc: 0.8658\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2897 - acc: 0.8949 - val_loss: 0.3806 - val_acc: 0.8660\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2851 - acc: 0.8952 - val_loss: 0.3809 - val_acc: 0.8655\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.2810 - acc: 0.8966 - val_loss: 0.3808 - val_acc: 0.8655\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.2788 - acc: 0.8978 - val_loss: 0.3822 - val_acc: 0.8642\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2731 - acc: 0.8993 - val_loss: 0.3768 - val_acc: 0.8654\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2710 - acc: 0.9004 - val_loss: 0.3786 - val_acc: 0.8643\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2658 - acc: 0.9035 - val_loss: 0.3762 - val_acc: 0.8677\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2624 - acc: 0.9042 - val_loss: 0.3791 - val_acc: 0.8681\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2607 - acc: 0.9034 - val_loss: 0.3759 - val_acc: 0.8670\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2579 - acc: 0.9048 - val_loss: 0.3758 - val_acc: 0.8675\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2567 - acc: 0.9054 - val_loss: 0.3775 - val_acc: 0.8655\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2509 - acc: 0.9084 - val_loss: 0.3777 - val_acc: 0.8663\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2477 - acc: 0.9102 - val_loss: 0.3841 - val_acc: 0.8677\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2449 - acc: 0.9101 - val_loss: 0.3778 - val_acc: 0.8680\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2398 - acc: 0.9118 - val_loss: 0.3842 - val_acc: 0.8664\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2388 - acc: 0.9125 - val_loss: 0.3809 - val_acc: 0.8660\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2350 - acc: 0.9132 - val_loss: 0.3875 - val_acc: 0.8659\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2325 - acc: 0.9144 - val_loss: 0.3789 - val_acc: 0.8697\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2273 - acc: 0.9167 - val_loss: 0.3813 - val_acc: 0.8699\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "Evaluating on TEST data\n",
      "loss 0.39838146321773527\n",
      "acc 0.8676\n"
     ]
    }
   ],
   "source": [
    "# Final training with \"best\" parameters and evaluation against test set\n",
    "# model2: Best: 0.898540 using {'learning_rate': 0.01, 'momentum': 0.8}\n",
    "# model3: Best: 0.863560 using {'learning_rate': 0.001, 'momentum': 0.9}\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "run(\n",
    "    model2(\n",
    "        learning_rate=0.01, momentum=0.8),\n",
    "    epochs=epochs, batch_size=batch_size, eval_test=True)\n",
    "run_model3(\n",
    "    model3(\n",
    "        learning_rate=0.001, momentum=0.9\n",
    "    ), epochs=epochs, batch_size=batch_size, eval_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled model2 with lr=0.01 momentum=0.8, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 16)        2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 16)          1040      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 56,042\n",
      "Trainable params: 56,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.8682 - acc: 0.7349 - val_loss: 0.5852 - val_acc: 0.8268\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.5617 - acc: 0.8246 - val_loss: 0.4844 - val_acc: 0.8429\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.4917 - acc: 0.8388 - val_loss: 0.4404 - val_acc: 0.8508\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.4550 - acc: 0.8484 - val_loss: 0.4191 - val_acc: 0.8585\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.4296 - acc: 0.8556 - val_loss: 0.3957 - val_acc: 0.8653\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.4118 - acc: 0.8610 - val_loss: 0.3965 - val_acc: 0.8650\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3995 - acc: 0.8650 - val_loss: 0.3766 - val_acc: 0.8735\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3887 - acc: 0.8685 - val_loss: 0.3624 - val_acc: 0.8746\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3788 - acc: 0.8733 - val_loss: 0.3745 - val_acc: 0.8685\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3682 - acc: 0.8765 - val_loss: 0.3660 - val_acc: 0.8720\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3615 - acc: 0.8779 - val_loss: 0.3492 - val_acc: 0.8823\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3528 - acc: 0.8816 - val_loss: 0.3510 - val_acc: 0.8801\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3483 - acc: 0.8820 - val_loss: 0.3485 - val_acc: 0.8787\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3438 - acc: 0.8852 - val_loss: 0.3333 - val_acc: 0.8864\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3375 - acc: 0.8869 - val_loss: 0.3523 - val_acc: 0.8744\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3297 - acc: 0.8911 - val_loss: 0.3362 - val_acc: 0.8885\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3257 - acc: 0.8921 - val_loss: 0.3301 - val_acc: 0.8895\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3205 - acc: 0.8934 - val_loss: 0.3334 - val_acc: 0.8885\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3167 - acc: 0.8955 - val_loss: 0.3197 - val_acc: 0.8945\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3144 - acc: 0.8940 - val_loss: 0.3176 - val_acc: 0.8935\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3087 - acc: 0.8981 - val_loss: 0.3114 - val_acc: 0.8963\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3042 - acc: 0.8983 - val_loss: 0.3199 - val_acc: 0.8919\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.3012 - acc: 0.8992 - val_loss: 0.3098 - val_acc: 0.8961\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2973 - acc: 0.9002 - val_loss: 0.3038 - val_acc: 0.8986\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2935 - acc: 0.9013 - val_loss: 0.3276 - val_acc: 0.8902\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2900 - acc: 0.9018 - val_loss: 0.3102 - val_acc: 0.8943\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2889 - acc: 0.9031 - val_loss: 0.3022 - val_acc: 0.8960\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2867 - acc: 0.9041 - val_loss: 0.3095 - val_acc: 0.8967\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2809 - acc: 0.9066 - val_loss: 0.2967 - val_acc: 0.9013\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2802 - acc: 0.9067 - val_loss: 0.3133 - val_acc: 0.8928\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2777 - acc: 0.9075 - val_loss: 0.3035 - val_acc: 0.8977\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2758 - acc: 0.9068 - val_loss: 0.3060 - val_acc: 0.8998\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2730 - acc: 0.9094 - val_loss: 0.3038 - val_acc: 0.8987\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2691 - acc: 0.9119 - val_loss: 0.2977 - val_acc: 0.9012\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2658 - acc: 0.9125 - val_loss: 0.3027 - val_acc: 0.8989\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2649 - acc: 0.9128 - val_loss: 0.2963 - val_acc: 0.9024\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2630 - acc: 0.9128 - val_loss: 0.3189 - val_acc: 0.8908\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2634 - acc: 0.9132 - val_loss: 0.3071 - val_acc: 0.9007\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2577 - acc: 0.9153 - val_loss: 0.3052 - val_acc: 0.8998\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2558 - acc: 0.9156 - val_loss: 0.2938 - val_acc: 0.9046\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2543 - acc: 0.9164 - val_loss: 0.2940 - val_acc: 0.9024\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2526 - acc: 0.9170 - val_loss: 0.2985 - val_acc: 0.9024\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2483 - acc: 0.9181 - val_loss: 0.3043 - val_acc: 0.8997\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2490 - acc: 0.9171 - val_loss: 0.3060 - val_acc: 0.8973\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2460 - acc: 0.9198 - val_loss: 0.3025 - val_acc: 0.8979\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2451 - acc: 0.9193 - val_loss: 0.2971 - val_acc: 0.9026\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2425 - acc: 0.9202 - val_loss: 0.2895 - val_acc: 0.9069\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2400 - acc: 0.9211 - val_loss: 0.3005 - val_acc: 0.8987\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2398 - acc: 0.9205 - val_loss: 0.3080 - val_acc: 0.9011\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2376 - acc: 0.9224 - val_loss: 0.2936 - val_acc: 0.9032\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2353 - acc: 0.9220 - val_loss: 0.2838 - val_acc: 0.9069\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2325 - acc: 0.9230 - val_loss: 0.2892 - val_acc: 0.9064\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2320 - acc: 0.9231 - val_loss: 0.2868 - val_acc: 0.9046\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2307 - acc: 0.9238 - val_loss: 0.2863 - val_acc: 0.9061\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2291 - acc: 0.9249 - val_loss: 0.2930 - val_acc: 0.9060\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2248 - acc: 0.9258 - val_loss: 0.3287 - val_acc: 0.8937\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2281 - acc: 0.9255 - val_loss: 0.2952 - val_acc: 0.9035\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2243 - acc: 0.9264 - val_loss: 0.2926 - val_acc: 0.9023\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2217 - acc: 0.9262 - val_loss: 0.2951 - val_acc: 0.9038\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2197 - acc: 0.9283 - val_loss: 0.2857 - val_acc: 0.9083\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2200 - acc: 0.9286 - val_loss: 0.3049 - val_acc: 0.9037\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2167 - acc: 0.9292 - val_loss: 0.2878 - val_acc: 0.9072\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2144 - acc: 0.9296 - val_loss: 0.2920 - val_acc: 0.9081\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2145 - acc: 0.9298 - val_loss: 0.2864 - val_acc: 0.9092\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2119 - acc: 0.9307 - val_loss: 0.2978 - val_acc: 0.9035\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2113 - acc: 0.9299 - val_loss: 0.2919 - val_acc: 0.9054\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2122 - acc: 0.9312 - val_loss: 0.2817 - val_acc: 0.9082\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2079 - acc: 0.9321 - val_loss: 0.2916 - val_acc: 0.9078\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2069 - acc: 0.9318 - val_loss: 0.2931 - val_acc: 0.9071\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2066 - acc: 0.9325 - val_loss: 0.3005 - val_acc: 0.9042\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2030 - acc: 0.9338 - val_loss: 0.2913 - val_acc: 0.9065\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1988 - acc: 0.9343 - val_loss: 0.3034 - val_acc: 0.9069\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2014 - acc: 0.9340 - val_loss: 0.2998 - val_acc: 0.9048\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.2018 - acc: 0.9349 - val_loss: 0.3222 - val_acc: 0.8980\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2002 - acc: 0.9349 - val_loss: 0.3063 - val_acc: 0.9040\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1944 - acc: 0.9367 - val_loss: 0.3005 - val_acc: 0.9061\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1966 - acc: 0.9358 - val_loss: 0.3121 - val_acc: 0.9045\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1960 - acc: 0.9348 - val_loss: 0.3060 - val_acc: 0.9063\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1929 - acc: 0.9374 - val_loss: 0.3006 - val_acc: 0.9045\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1930 - acc: 0.9369 - val_loss: 0.2945 - val_acc: 0.9090\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1917 - acc: 0.9382 - val_loss: 0.3080 - val_acc: 0.9043\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.1888 - acc: 0.9398 - val_loss: 0.2908 - val_acc: 0.9114\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1876 - acc: 0.9394 - val_loss: 0.2993 - val_acc: 0.9084\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1879 - acc: 0.9397 - val_loss: 0.2931 - val_acc: 0.9082\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1844 - acc: 0.9401 - val_loss: 0.3110 - val_acc: 0.9069\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1835 - acc: 0.9409 - val_loss: 0.3039 - val_acc: 0.9073\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.1842 - acc: 0.9411 - val_loss: 0.3067 - val_acc: 0.9090\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1861 - acc: 0.9391 - val_loss: 0.3006 - val_acc: 0.9086\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1813 - acc: 0.9421 - val_loss: 0.3011 - val_acc: 0.9046\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1784 - acc: 0.9430 - val_loss: 0.2996 - val_acc: 0.9095\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1810 - acc: 0.9413 - val_loss: 0.2988 - val_acc: 0.9123\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1761 - acc: 0.9429 - val_loss: 0.3082 - val_acc: 0.9054\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1778 - acc: 0.9425 - val_loss: 0.3016 - val_acc: 0.9098\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.1768 - acc: 0.9422 - val_loss: 0.2999 - val_acc: 0.9087\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1772 - acc: 0.9434 - val_loss: 0.3016 - val_acc: 0.9096\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.1736 - acc: 0.9450 - val_loss: 0.3172 - val_acc: 0.9063\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1742 - acc: 0.9437 - val_loss: 0.3120 - val_acc: 0.9078\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1717 - acc: 0.9451 - val_loss: 0.2988 - val_acc: 0.9106\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.1717 - acc: 0.9449 - val_loss: 0.3070 - val_acc: 0.9092\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.1717 - acc: 0.9445 - val_loss: 0.3106 - val_acc: 0.9066\n",
      "Evaluating on TEST data\n",
      "loss 0.33037412548065187\n",
      "acc 0.9048\n",
      "Compiled model3 with lr=0.001 momentum=0.9, decay=1e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 205,642\n",
      "Trainable params: 205,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "epochs 100\n",
      "batch_size 128\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.0754 - acc: 0.6458 - val_loss: 0.6696 - val_acc: 0.7783\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.6745 - acc: 0.7712 - val_loss: 0.5710 - val_acc: 0.8057\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.5886 - acc: 0.7950 - val_loss: 0.5249 - val_acc: 0.8191\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5393 - acc: 0.8099 - val_loss: 0.4999 - val_acc: 0.8243\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.5094 - acc: 0.8198 - val_loss: 0.4716 - val_acc: 0.8323\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4788 - acc: 0.8295 - val_loss: 0.4610 - val_acc: 0.8358\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4627 - acc: 0.8350 - val_loss: 0.4468 - val_acc: 0.8380\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4475 - acc: 0.8402 - val_loss: 0.4363 - val_acc: 0.8464\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4306 - acc: 0.8459 - val_loss: 0.4277 - val_acc: 0.8481\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4191 - acc: 0.8510 - val_loss: 0.4235 - val_acc: 0.8487\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4075 - acc: 0.8555 - val_loss: 0.4165 - val_acc: 0.8492\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3992 - acc: 0.8544 - val_loss: 0.4084 - val_acc: 0.8517\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3908 - acc: 0.8594 - val_loss: 0.4107 - val_acc: 0.8523\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3818 - acc: 0.8620 - val_loss: 0.4012 - val_acc: 0.8548\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3728 - acc: 0.8649 - val_loss: 0.4015 - val_acc: 0.8527\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3661 - acc: 0.8677 - val_loss: 0.3960 - val_acc: 0.8569\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3594 - acc: 0.8689 - val_loss: 0.3941 - val_acc: 0.8571\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3518 - acc: 0.8729 - val_loss: 0.3938 - val_acc: 0.8588\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3463 - acc: 0.8736 - val_loss: 0.3889 - val_acc: 0.8581\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3415 - acc: 0.8770 - val_loss: 0.3874 - val_acc: 0.8597\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3356 - acc: 0.8783 - val_loss: 0.3867 - val_acc: 0.8596\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3297 - acc: 0.8802 - val_loss: 0.3906 - val_acc: 0.8624\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3247 - acc: 0.8817 - val_loss: 0.3834 - val_acc: 0.8609\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3217 - acc: 0.8827 - val_loss: 0.3834 - val_acc: 0.8637\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3153 - acc: 0.8842 - val_loss: 0.3803 - val_acc: 0.8663\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3116 - acc: 0.8863 - val_loss: 0.3848 - val_acc: 0.8589\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3064 - acc: 0.8889 - val_loss: 0.3807 - val_acc: 0.8633\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3026 - acc: 0.8899 - val_loss: 0.3793 - val_acc: 0.8658\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2986 - acc: 0.8909 - val_loss: 0.3772 - val_acc: 0.8644\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.2958 - acc: 0.8907 - val_loss: 0.3824 - val_acc: 0.8628\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.2883 - acc: 0.8942 - val_loss: 0.3767 - val_acc: 0.8690\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2877 - acc: 0.8933 - val_loss: 0.3808 - val_acc: 0.8656\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2817 - acc: 0.8978 - val_loss: 0.3807 - val_acc: 0.8672\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2797 - acc: 0.8976 - val_loss: 0.3788 - val_acc: 0.8643\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2757 - acc: 0.8989 - val_loss: 0.3758 - val_acc: 0.8645\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2702 - acc: 0.9010 - val_loss: 0.3790 - val_acc: 0.8636\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2690 - acc: 0.9013 - val_loss: 0.3743 - val_acc: 0.8658\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2637 - acc: 0.9035 - val_loss: 0.3744 - val_acc: 0.8690\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2610 - acc: 0.9039 - val_loss: 0.3795 - val_acc: 0.8684\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2575 - acc: 0.9050 - val_loss: 0.3754 - val_acc: 0.8679\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2575 - acc: 0.9057 - val_loss: 0.3795 - val_acc: 0.8684\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2524 - acc: 0.9068 - val_loss: 0.3783 - val_acc: 0.8675\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2510 - acc: 0.9077 - val_loss: 0.3770 - val_acc: 0.8659\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2473 - acc: 0.9088 - val_loss: 0.3733 - val_acc: 0.8679\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2452 - acc: 0.9095 - val_loss: 0.3742 - val_acc: 0.8693\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2407 - acc: 0.9116 - val_loss: 0.3710 - val_acc: 0.8713\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2367 - acc: 0.9136 - val_loss: 0.3830 - val_acc: 0.8675\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2363 - acc: 0.9124 - val_loss: 0.3801 - val_acc: 0.8684\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.2275 - acc: 0.9160 - val_loss: 0.3822 - val_acc: 0.8689\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2290 - acc: 0.9161 - val_loss: 0.3786 - val_acc: 0.8660\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2249 - acc: 0.9168 - val_loss: 0.3778 - val_acc: 0.8712\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2224 - acc: 0.9180 - val_loss: 0.3800 - val_acc: 0.8695\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2211 - acc: 0.9194 - val_loss: 0.3766 - val_acc: 0.8688\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2181 - acc: 0.9197 - val_loss: 0.3796 - val_acc: 0.8692\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2147 - acc: 0.9220 - val_loss: 0.3843 - val_acc: 0.8660\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2135 - acc: 0.9216 - val_loss: 0.3800 - val_acc: 0.8706\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.2120 - acc: 0.9208 - val_loss: 0.3827 - val_acc: 0.8683\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2080 - acc: 0.9237 - val_loss: 0.3829 - val_acc: 0.8713\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.2045 - acc: 0.9241 - val_loss: 0.3775 - val_acc: 0.8702\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2012 - acc: 0.9256 - val_loss: 0.3818 - val_acc: 0.8698\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2007 - acc: 0.9263 - val_loss: 0.3830 - val_acc: 0.8710\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.2014 - acc: 0.9255 - val_loss: 0.3820 - val_acc: 0.8701\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1969 - acc: 0.9284 - val_loss: 0.3826 - val_acc: 0.8700\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1936 - acc: 0.9282 - val_loss: 0.3854 - val_acc: 0.8699\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1915 - acc: 0.9293 - val_loss: 0.3918 - val_acc: 0.8690\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1910 - acc: 0.9293 - val_loss: 0.3942 - val_acc: 0.8703\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1880 - acc: 0.9306 - val_loss: 0.3934 - val_acc: 0.8706\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1860 - acc: 0.9307 - val_loss: 0.3939 - val_acc: 0.8702\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.1835 - acc: 0.9323 - val_loss: 0.3922 - val_acc: 0.8717\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1807 - acc: 0.9325 - val_loss: 0.3946 - val_acc: 0.8715\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1803 - acc: 0.9324 - val_loss: 0.3962 - val_acc: 0.8682\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1770 - acc: 0.9346 - val_loss: 0.3958 - val_acc: 0.8681\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1761 - acc: 0.9353 - val_loss: 0.3951 - val_acc: 0.8698\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1738 - acc: 0.9365 - val_loss: 0.4007 - val_acc: 0.8718\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1726 - acc: 0.9367 - val_loss: 0.4026 - val_acc: 0.8704\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1708 - acc: 0.9383 - val_loss: 0.3945 - val_acc: 0.8717\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.1686 - acc: 0.9377 - val_loss: 0.4089 - val_acc: 0.8694\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1683 - acc: 0.9379 - val_loss: 0.4068 - val_acc: 0.8702\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1615 - acc: 0.9403 - val_loss: 0.4092 - val_acc: 0.8724\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.1617 - acc: 0.9406 - val_loss: 0.4063 - val_acc: 0.8719\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1612 - acc: 0.9400 - val_loss: 0.4131 - val_acc: 0.8699\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1603 - acc: 0.9408 - val_loss: 0.4106 - val_acc: 0.8684\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1599 - acc: 0.9404 - val_loss: 0.4101 - val_acc: 0.8709\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1559 - acc: 0.9426 - val_loss: 0.4170 - val_acc: 0.8681\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1547 - acc: 0.9427 - val_loss: 0.4155 - val_acc: 0.8697\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1509 - acc: 0.9449 - val_loss: 0.4182 - val_acc: 0.8711\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1506 - acc: 0.9450 - val_loss: 0.4163 - val_acc: 0.8714\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1476 - acc: 0.9451 - val_loss: 0.4155 - val_acc: 0.8692\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.1465 - acc: 0.9461 - val_loss: 0.4158 - val_acc: 0.8701\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1451 - acc: 0.9474 - val_loss: 0.4262 - val_acc: 0.8668\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1453 - acc: 0.9467 - val_loss: 0.4264 - val_acc: 0.8681\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1442 - acc: 0.9471 - val_loss: 0.4301 - val_acc: 0.8662\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1403 - acc: 0.9474 - val_loss: 0.4310 - val_acc: 0.8643\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1417 - acc: 0.9478 - val_loss: 0.4294 - val_acc: 0.8706\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1378 - acc: 0.9498 - val_loss: 0.4256 - val_acc: 0.8679\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.1368 - acc: 0.9505 - val_loss: 0.4437 - val_acc: 0.8698\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1371 - acc: 0.9491 - val_loss: 0.4351 - val_acc: 0.8681\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.1340 - acc: 0.9508 - val_loss: 0.4330 - val_acc: 0.8689\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.1310 - acc: 0.9521 - val_loss: 0.4346 - val_acc: 0.8661\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.1323 - acc: 0.9516 - val_loss: 0.4340 - val_acc: 0.8685\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "Evaluating on TEST data\n",
      "loss 0.4605405102372169\n",
      "acc 0.8672\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "run(\n",
    "    model2(\n",
    "        learning_rate=0.01, momentum=0.8),\n",
    "    epochs=epochs, batch_size=batch_size, eval_test=True)\n",
    "run_model3(\n",
    "    model3(\n",
    "        learning_rate=0.001, momentum=0.9\n",
    "    ), epochs=epochs, batch_size=batch_size, eval_test=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
